<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"/><meta name="theme-color" content="#222"/><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"/><meta name="renderer" content="webkit"/><link rel="icon" type="image/ico" sizes="32x32" href="/assets/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"/><link rel="alternate" href="/rss.xml" title="木语" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="木语" type="application/atom+xml"><link rel="alternate" type="application/json" title="木语" href="https://koen666.github.io/feed.json"/><link rel="preconnect" href="https://s4.zstatic.net"/><link rel="preconnect" href="https://at.alicdn.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="modulepreload" href="/js/siteInit.js"></link><link rel="modulepreload" href="/js/nyx-player-RT6Y6A2P.js"></link><link rel="modulepreload" href="/js/copy-tex-XZBHQKN2.js"></link><link rel="modulepreload" href="/js/post-2QNEWI46.js"></link><link rel="modulepreload" href="/js/chunk-KZR3QQFA.js"></link><link rel="modulepreload" href="/js/index.esm-JYVAQ62Y.js"></link><link rel="modulepreload" href="/js/chunk-RK7HQRIO.js"></link><link rel="modulepreload" href="/js/chunk-FQAC5HAL.js"></link><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="preload" href="/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E4%BA%8C%E6%AC%A1%E5%85%83%E7%BE%8E%E5%A5%B3-%E5%8A%A8%E6%BC%AB.png" as="image" fetchpriority="high"><link rel="preload" href="/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%88%9D%E9%9F%B3%E6%9C%AA%E6%9D%A5-%E5%8A%A8%E6%BC%AB.png" as="image" fetchpriority="high"><link rel="preload" href="/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9-%E6%B5%B7%E6%B4%8B%E5%A5%B3%E5%AD%A9.png" as="image" fetchpriority="high"><link rel="preload" href="/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9-%E6%B5%B7%E6%B4%8B%E5%A5%B3%E5%AD%A9.png" as="image" fetchpriority="high"><link rel="preload" href="/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E4%BA%8C%E6%AC%A1%E5%85%83%E7%BE%8E%E5%A5%B3-%E5%8A%A8%E6%BC%AB.png" as="image" fetchpriority="high"><link rel="preload" href="/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9-%E5%92%8C%E6%A0%97%E8%96%B0%E5%AD%90.png" as="image" fetchpriority="high"><meta name="keywords" content="deeplearning,Transformer"/><meta name="description" content="本文介绍pytorch的基本使用，深度学习基础算法和神经网络的构建知识"/><link rel="canonical" href="https://koen666.github.io/2025/07/26/pytorch/"><link rel="stylesheet" href="/css/post.css?v=0.5.4"><link rel="stylesheet" href="/css/mermaid.css?v=0.5.4"><!-- 临时处理--><link rel="stylesheet" media="none" onload="this.media='all'" href="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.css"><title>Pytorch，深度学习与神经网络篇</title><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="pagefind_mount"></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Pytorch，深度学习与神经网络篇</h1><div class="meta"><span class="item" title="创建时间：2025-07-26 16:06:04"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">发表于</span><time itemprop="dateCreated datePublished" datetime="2025-07-26T16:06:04+08:00">2025-07-26</time></span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i></span><span class="text">本文字数</span><span>43k</span><span class="text">字</span></span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i></span><span class="text">阅读时长</span><span>39 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">木语</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><ul><li class="item" style="background-image: url(&quot;/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E4%BA%8C%E6%AC%A1%E5%85%83%E7%BE%8E%E5%A5%B3-%E5%8A%A8%E6%BC%AB.png&quot;);"></li><li class="item" style="background-image: url(&quot;/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%88%9D%E9%9F%B3%E6%9C%AA%E6%9D%A5-%E5%8A%A8%E6%BC%AB.png&quot;);"></li><li class="item" style="background-image: url(&quot;/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9-%E6%B5%B7%E6%B4%8B%E5%A5%B3%E5%AD%A9.png&quot;);"></li><li class="item" style="background-image: url(&quot;/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9-%E6%B5%B7%E6%B4%8B%E5%A5%B3%E5%AD%A9.png&quot;);"></li><li class="item" style="background-image: url(&quot;/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E4%BA%8C%E6%AC%A1%E5%85%83%E7%BE%8E%E5%A5%B3-%E5%8A%A8%E6%BC%AB.png&quot;);"></li><li class="item" style="background-image: url(&quot;/images/bg/%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9-%E5%92%8C%E6%A0%97%E8%96%B0%E5%AD%90.png&quot;);"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemListElement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">首页</a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/pytorch/" itemprop="item" rel="index" title="分类于pytorch"><span itemprop="name">pytorch<meta itemprop="position" content="0"/></span></a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" data-pagefind-body="data-pagefind-body" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://koen666.github.io/2025/07/26/pytorch/"/><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/head.png"/><meta itemprop="name" content="koen"/><meta itemprop="description" content="技术是逻辑，木是自然，语是表达, Spark!"/></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="木语"/></span><div class="body md" itemprop="articleBody"><p>首先给大家介绍一下深度学习的基本框架</p>
<p>深度学习是以神经网络为基础的机器学习方法，其中包括多种网络结构（如 FNN、CNN、RNN、Transformer 等），<br>
这些基础结构构成了实现各种功能性模型的核心模块，例如：</p>
<p><img loading="lazy" src="/images/pytorch/GAN.png" alt="GAN（生成对抗网络）"></p>
<p><img loading="lazy" src="/images/pytorch/Auto-encoder.png" alt="Auto-Encoder（自编码器）"></p>
<p>VAE（变分自编码器）</p>
<p>BERT、GPT 等预训练模型</p>
<p>基础结构（Network Architectures）</p>
<ul>
<li>FNN（前馈神经网络）</li>
<li>CNN（卷积神经网络）</li>
<li>RNN（循环神经网络）</li>
<li>Transformer（注意力机制为核心）</li>
</ul>
<p>功能性模型（Functional Models / Applications）</p>
<ul>
<li>自编码器 Auto-Encoder（FNN/CNN）</li>
<li>生成对抗网络 GAN（FNN/CNN）</li>
<li>变分自编码器 VAE（FNN）</li>
<li>强化学习策略网络（FNN/RNN）</li>
<li>GPT、BERT 等 NLP 模型（Transformer）</li>
<li>其他任务模型
<ul>
<li>UNet</li>
<li>ResNet</li>
<li>YOLO</li>
</ul>
</li>
</ul>
<h2 id="一-autograd"><a class="anchor" href="#一-autograd">#</a> 一、AutoGrad</h2>
<p>autograd 包是 PyTorch 中所有神经网络的核心。首先让我们简要地介绍它，然后我们将会去训练我们的第一个神经网络。该 autograd 软件包为 Tensors 上的所有操作提供自动微分。它是一个由运行定义的框架，这意味着以代码运行方式定义你的后向传播，并且每次迭代都可以不同</p>
<p>先丢张思维导图叭：<br>
<img loading="lazy" src="/images/pytorch/autograd.png" alt="autograd"></p>
<p>首先要给x定义 <code>requires_grad=True</code> 属性</p>
<p>其次要注意被<code>backward()</code>的张量需要是张量标量，即需要被<code>mean()</code>或者是<code>sum()</code></p>
<p>最后x的梯度就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>d</mi><mi>z</mi></mrow><mrow><mi>d</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{dz}{dx}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">x</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>将代码块包裹在 <code>with torch.no_grad()：</code> 中以停止自动微分</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">x.requires_grad</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">x</span><span style="color:#A65E2B;--shiki-dark:#C99076"> **</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 2</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.requires_grad</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">with</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.no_grad</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">    print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">x</span><span style="color:#A65E2B;--shiki-dark:#C99076"> **</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 2</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.requires_grad</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>output:</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">True</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">True</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">False</span></span></code></pre>
<hr>
<h2 id="二-神经网络基础"><a class="anchor" href="#二-神经网络基础">#</a> 二、神经网络基础</h2>
<h3 id="21-了解神经网络结构的分类"><a class="anchor" href="#21-了解神经网络结构的分类">#</a> 2.1 了解神经网络结构的分类</h3>
<table>
<thead>
<tr>
<th>序号</th>
<th>网络类型</th>
<th>简介</th>
<th>适用场景</th>
<th>代表模型 / 特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>前馈神经网络（FNN）</td>
<td>最基础的神经网络，信息单向传播，无环</td>
<td>通用场景</td>
<td>多层感知器（MLP）</td>
</tr>
<tr>
<td>2</td>
<td>卷积神经网络（CNN）</td>
<td>提取图像局部特征，参数更少</td>
<td>图像识别、目标检测</td>
<td>LeNet、AlexNet、VGG、ResNet、EfficientNet</td>
</tr>
<tr>
<td>3</td>
<td>循环神经网络（RNN）</td>
<td>处理序列数据，有“记忆”结构</td>
<td>文本、语音、时间序列</td>
<td>RNN、LSTM、GRU</td>
</tr>
<tr>
<td>4</td>
<td>残差神经网络（ResNet）</td>
<td>使用残差连接避免梯度消失</td>
<td>深层网络训练</td>
<td>ResNet、输出=F(x)+x</td>
</tr>
<tr>
<td>5</td>
<td>图神经网络（GNN）</td>
<td>适用于图结构数据</td>
<td>社交网络、知识图谱</td>
<td>GCN、GAT、GraphSAGE</td>
</tr>
</tbody>
</table>
<h3 id="22-了解神经网络的整个过程"><a class="anchor" href="#22-了解神经网络的整个过程">#</a> 2.2 了解神经网络的整个过程</h3>
<p><code>输入数据 x                    输入层有几个神经元就输入几个数据（几维）</code></p>
<p><code>正向传播（Linear + 激活函数）  隐藏层=线性层+激活函数（模拟复杂的数据分布）</code></p>
<p><code>输出结果（预测值）</code></p>
<p><code>计算损失（Loss 与真实值比较）</code></p>
<p><code>反向传播（链式法则求导）</code></p>
<p><code>参数梯度更新（Optimizer）</code></p>
<p><code>下一轮训练</code></p>
<p>损失函数：计算"偏差"</p>
<p>优化器：这个“偏差”通过损失函数计算出来，而优化器的工作，就是 通过反向传播得到的梯度，更新参数，使损失越来越小</p>
<p>给出一个简单的前馈神经网络作为实例进行讲解</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.nn</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.optim</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> optim</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 定义一个简单的前馈神经网络，包含一个隐藏层</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">class</span><span style="color:#B56959;--shiki-dark:#C98A7D"> SimpleFNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">nn.Module</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        super</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">SimpleFNN,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#59873A;--shiki-dark:#80A665">.__init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.fc1</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">4,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 8</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">   # 输入层4个特征，隐藏层8个神经元</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.relu</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.ReLU</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 激活函数</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.fc2</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">8,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 3</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">   # 输出层3个类别（比如3分类问题）</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> forward</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.fc1</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.relu</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.fc2</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">        return</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建模型</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">model</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> SimpleFNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">model</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 假设输入是4维特征</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">sample_input</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.randn</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">2,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 4</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # batch_size=2，4个特征</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">output</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> model</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">sample_input</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">output</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span></code></pre>
<p><code>__init__ </code>函数 — 网络结构的“搭建工厂”</p>
<p>作用：<br>
初始化神经网络的层和组件,相当于在这里定义好网络的“骨架”和“零件”。</p>
<p>一般<code>_init_</code>内包含如下内容:</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>内容</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>🔷 网络层</td>
<td><code>nn.Linear</code>, <code>nn.Conv2d</code>, <code>nn.LSTM</code> 等</td>
<td>定义输入层、隐藏层、输出层结构</td>
</tr>
<tr>
<td>🔶 激活函数</td>
<td><code>nn.ReLU()</code>, <code>nn.Sigmoid()</code> 等</td>
<td>可以作为类成员，也可以直接在 <code>forward()</code> 里用</td>
</tr>
<tr>
<td>🔸 Dropout / BatchNorm</td>
<td><code>nn.Dropout</code>, <code>nn.BatchNorm1d</code> 等</td>
<td>用于正则化、加速收敛</td>
</tr>
<tr>
<td>🔻 有时会放优化器 / 损失函数（但不推荐）</td>
<td><code>optim.SGD</code>, <code>nn.CrossEntropyLoss</code></td>
<td>一般在模型外单独写更清晰</td>
</tr>
</tbody>
</table>
<p>比如在上述示例代码中的具体内容：</p>
<ul>
<li>
<p><code>super(SimpleFNN, self).__init__()</code><br>
调用父类 nn.Module 的初始化方法，确保网络能正常工作和注册所有子模块。</p>
</li>
<li>
<p><code>self.fc1 = nn.Linear(4, 8)</code><br>
定义第一个全连接层（线性层），它接受4维输入，输出8维数据。<br>
这层会学习一个 4×8 的权重矩阵和偏置向量。</p>
</li>
<li>
<p><code>self.relu = nn.ReLU()</code><br>
定义了一个激活函数ReLU，增加网络的非线性表达能力。<br>
这里是先定义好，可以在 forward 中调用。</p>
</li>
<li>
<p><code>self.fc2 = nn.Linear(8, 3)</code><br>
定义第二个全连接层，接受8维输入，输出3维结果。<br>
这常用作分类任务的输出层，输出3个类别的分数。</p>
</li>
</ul>
<p><code>forward</code> 函数 — 数据的“运行流程”,里面定义的是从"输入到输出"的这一整条路线</p>
<p>作用：<br>
定义输入数据如何通过网络计算得到输出。<br>
相当于网络的“运行步骤”，告诉 PyTorch 具体执行什么操作。</p>
<p>具体流程：</p>
<ul>
<li>
<p><code>x = self.fc1(x)</code><br>
输入数据 x 先经过第一个全连接层，变成8维的向量。</p>
</li>
<li>
<p><code>x = self.relu(x)</code><br>
将刚得到的8维数据通过 ReLU 激活函数，增加非线性。<br>
ReLU的作用是把负数变为0，正数保持不变。</p>
</li>
<li>
<p><code>x = self.fc2(x)</code><br>
再把激活后的结果输入到第二个全连接层，变成3维输出。</p>
</li>
<li>
<p><code>return x</code><br>
返回最终输出，通常是“分类分数”或“回归预测值”。</p>
</li>
</ul>
<h3 id="23激活函数"><a class="anchor" href="#23激活函数">#</a> 2.3激活函数</h3>
<table>
<thead>
<tr>
<th>激活函数</th>
<th>数学形式</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ReLU</strong></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) = \max(0, x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></td>
<td>简单高效，梯度传播好，但会有"死神经元"问题</td>
</tr>
<tr>
<td><strong>Sigmoid</strong></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x) = \frac{1}{1 + e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></td>
<td>输出在(0,1)，容易梯度消失</td>
</tr>
<tr>
<td><strong>Tanh</strong></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3907em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9874em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5935em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7385em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8477em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></td>
<td>输出在(-1,1)，比Sigmoid对称，但也可能梯度消失</td>
</tr>
<tr>
<td><strong>Leaky ReLU</strong></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0.01</mn><mi>x</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) = \max(0.01x, x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0.01</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></td>
<td>解决ReLU死区问题</td>
</tr>
<tr>
<td><strong>ELU</strong></td>
<td>指数线性单元</td>
<td>更平滑的梯度流</td>
</tr>
</tbody>
</table>
<p>作用：激活函数让隐藏层拥有表达复杂模式的能力，是神经网络“聪明起来”的关键。</p>
<h3 id="24损失函数"><a class="anchor" href="#24损失函数">#</a> 2.4损失函数</h3>
<table>
<thead>
<tr>
<th>名称</th>
<th>适用任务</th>
<th>PyTorch 对应函数</th>
<th>公式/描述</th>
<th>特点与使用场景</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>均方误差（MSE）</strong></td>
<td>回归</td>
<td><code>nn.MSELoss</code></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{1}{n} \sum (y_i - \hat{y}_i)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></td>
<td>对异常值敏感；常用于回归</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>平均绝对误差（MAE）</strong></td>
<td>回归</td>
<td><code>nn.L1Loss</code></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\frac{1}{n} \sum y_i - \hat{y}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></td>
<td>抗异常值能力强，收敛速度慢</td>
</tr>
<tr>
<td><strong>交叉熵损失（Cross Entropy）</strong></td>
<td>分类</td>
<td><code>nn.CrossEntropyLoss</code></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mo>∑</mo><msub><mi>y</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-\sum y_i \log(\hat{y}_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></td>
<td>多分类常用，内置了 <code>LogSoftmax</code> + <code>NLLLoss</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>二分类交叉熵（BCE）</strong></td>
<td>二分类</td>
<td><code>nn.BCELoss</code> or <code>nn.BCEWithLogitsLoss</code></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mo stretchy="false">[</mo><mi>y</mi><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">-[y \log(\hat{y}) + (1-y)\log(1-\hat{y})]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)]</span></span></span></span></td>
<td>二分类常用；<code>BCEWithLogitsLoss</code>更稳定，内部自带sigmoid</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>KL散度（KL Divergence）</strong></td>
<td>分布匹配</td>
<td><code>nn.KLDivLoss</code></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sum p(x) \log\left(\frac{p(x)}{q(x)}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></td>
<td>用于衡量两个概率分布之间的差距</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>负对数似然损失（NLL）</strong></td>
<td>分类</td>
<td><code>nn.NLLLoss</code></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mtext>true</mtext></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-\log(p_{\text{true}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">true</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></td>
<td>通常和 <code>LogSoftmax</code> 一起用</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Huber 损失</strong></td>
<td>回归（稳健）</td>
<td><code>nn.SmoothL1Loss</code></td>
<td>结合 MAE 和 MSE 的优点</td>
<td>对离群值鲁棒，适合有噪声的回归问题</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>多标签 Soft Margin 损失</strong></td>
<td>多标签分类</td>
<td><code>nn.MultiLabelSoftMarginLoss</code></td>
<td>基于每个标签的 sigmoid + binary cross-entropy</td>
<td>多标签多分类（每个样本可以属于多个类）</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>CTC 损失（Connectionist Temporal Classification）</strong></td>
<td>序列学习</td>
<td><code>nn.CTCLoss</code></td>
<td>解决输入输出长度不对齐的问题（如语音识别）</td>
<td>不需要对齐的标签，适合语音、OCR等</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Triplet Loss</strong></td>
<td>度量学习</td>
<td><code>nn.TripletMarginLoss</code></td>
<td>让 anchor 更接近 positive，远离 negative</td>
<td>常用于人脸识别、图像检索等</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Cosine Embedding Loss</strong></td>
<td>度量学习</td>
<td><code>nn.CosineEmbeddingLoss</code></td>
<td>基于余弦相似度的正负样本对学习</td>
<td>学习语义相似的嵌入表示（embedding）</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="25优化器"><a class="anchor" href="#25优化器">#</a> 2.5优化器</h3>
<table>
<thead>
<tr>
<th>优化器名称</th>
<th>PyTorch 类</th>
<th>特点</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SGD（随机梯度下降）</strong></td>
<td><code>torch.optim.SGD</code></td>
<td>最基础的优化器</td>
<td>可搭配 Momentum 使用</td>
</tr>
<tr>
<td><strong>SGD + Momentum</strong></td>
<td><code>torch.optim.SGD(momentum=0.9)</code></td>
<td>缓冲梯度方向，减少震荡</td>
<td>比单纯 SGD 更快收敛</td>
</tr>
<tr>
<td><strong>Adagrad</strong></td>
<td><code>torch.optim.Adagrad</code></td>
<td>对稀疏梯度参数有优势</td>
<td>可能学习率过早变小</td>
</tr>
<tr>
<td><strong>RMSprop</strong></td>
<td><code>torch.optim.RMSprop</code></td>
<td>控制学习率衰减</td>
<td>推荐用于 RNN</td>
</tr>
<tr>
<td><strong>Adam</strong></td>
<td><code>torch.optim.Adam</code></td>
<td>自适应 + 动量</td>
<td>最常用优化器之一</td>
</tr>
<tr>
<td><strong>AdamW</strong></td>
<td><code>torch.optim.AdamW</code></td>
<td>改进的 Adam，加权衰减更科学</td>
<td>推荐用于 Transformer</td>
</tr>
<tr>
<td><strong>Adadelta</strong></td>
<td><code>torch.optim.Adadelta</code></td>
<td>改进 Adagrad，避免学习率消失</td>
<td>少用但可选</td>
</tr>
<tr>
<td><strong>NAdam</strong></td>
<td><code>torch.optim.NAdam</code></td>
<td>Adam + Nesterov 动量</td>
<td>更快的收敛性</td>
</tr>
<tr>
<td><strong>RAdam</strong></td>
<td><code>torch.optim.RAdam</code></td>
<td>修正初始训练阶段不稳定</td>
<td>更鲁棒于训练初期</td>
</tr>
<tr>
<td><strong>LAMB</strong></td>
<td>无官方支持（用 HuggingFace 优化器）</td>
<td>大模型（如 BERT）适用</td>
<td>用于大 batch 训练</td>
</tr>
<tr>
<td><strong>AdaBelief</strong></td>
<td>第三方库</td>
<td>改进 Adam，使更新更像 SGD</td>
<td>收敛快 + 泛化强</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="26整个神经网络过程"><a class="anchor" href="#26整个神经网络过程">#</a> 2.6整个神经网络过程</h3>
<p>综上所述，我们得到一个神经网络的整个过程，根据上面已经定义好的前馈神经网络进行一个简单补充</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.nn</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.optim</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> optim</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 定义一个简单的前馈神经网络（输入层 → 隐藏层 → 输出层）</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">class</span><span style="color:#B56959;--shiki-dark:#C98A7D"> SimpleFNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">nn.Module</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        super</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">SimpleFNN,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#59873A;--shiki-dark:#80A665">.__init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.fc1</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">4,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 8</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">   # 输入层4个特征，隐藏层8个神经元</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.relu</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.ReLU</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 激活函数</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.fc2</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">8,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 3</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">   # 输出层3个类别（适合做分类）</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> forward</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.fc1</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.relu</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.fc2</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">        return</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 输出为 logits，未经过 softmax</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建模型实例</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">model</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> SimpleFNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">model</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建一个样本输入：batch_size=2，4个特征,2个样本+4个特征</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">sample_input</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.randn</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">2,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 4</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"Input:\n"</span><span style="color:#59873A;--shiki-dark:#80A665">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> sample_input</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 假设真实标签（ground truth），batch 中两个样本分别是类 1 和类 2</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">labels</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, 2</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 定义损失函数：交叉熵损失用于多分类问题</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">criterion</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.CrossEntropyLoss</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 定义优化器：SGD优化器，学习率为0.01</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">optimizer</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> optim.SGD</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">model.parameters</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B07D48;--shiki-dark:#BD976A">lr</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">0.01</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># ----------- 模拟一次训练步骤 -----------</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 前向传播：将输入送入模型</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">outputs</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> model</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">sample_input</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"Model raw output (logits):\n"</span><span style="color:#59873A;--shiki-dark:#80A665">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> outputs</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 计算损失（CrossEntropyLoss内部包含了softmax）</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">loss</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> criterion</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">outputs,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> labels</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"Loss:"</span><span style="color:#59873A;--shiki-dark:#80A665">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> loss.item</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 清空之前的梯度</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">optimizer.zero_grad</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 反向传播：自动计算梯度</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">loss.backward</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 更新权重和偏置</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">optimizer.step</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span></code></pre>
<hr>
<h2 id="三-数据的处理和加载"><a class="anchor" href="#三-数据的处理和加载">#</a> 三、数据的处理和加载</h2>
<h3 id="31dataset和dataloader"><a class="anchor" href="#31dataset和dataloader">#</a> 3.1Dataset和DataLoader</h3>
<p>Dataset本身是一个抽象类，允许你以它为父类定义一个自己的数据集</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">from</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.utils.data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> Dataset</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 自定义数据集类</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">class</span><span style="color:#B56959;--shiki-dark:#C98A7D"> MyDataset</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">Dataset</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> X_data,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> Y_data</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        """</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        初始化数据集，X_data 和 Y_data 是两个列表或数组</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        X_data: 输入特征</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        Y_data: 目标标签</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        """</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.X_data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> X_data</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.Y_data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> Y_data</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __len__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        """返回数据集的大小"""</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">        return</span><span style="color:#B56959;--shiki-dark:#C98A7D"> len</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self.X_data</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __getitem__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> idx</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        """返回指定索引的数据"""</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self.X_data</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#59873A;--shiki-dark:#80A665">idx</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#59873A;--shiki-dark:#80A665">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> dtype=torch.float32</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 转换为 Tensor</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self.Y_data</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#59873A;--shiki-dark:#80A665">idx</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#59873A;--shiki-dark:#80A665">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> dtype=torch.float32</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">        return</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> y</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 示例数据</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">X_data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, </span><span style="color:#B56959;--shiki-dark:#C98A7D">2],</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">3, </span><span style="color:#B56959;--shiki-dark:#C98A7D">4],</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">5, </span><span style="color:#B56959;--shiki-dark:#C98A7D">6],</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">7, </span><span style="color:#B56959;--shiki-dark:#C98A7D">8]]</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 输入特征</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">Y_data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, </span><span style="color:#B56959;--shiki-dark:#C98A7D">0,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 0]</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 目标标签</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建数据集实例    </span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">dataset</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> MyDataset</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">X_data,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> Y_data</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>DataLoader可以用于按批次(batch)从Dataset中加载数据</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">from</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.utils.data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> DataLoader</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建 DataLoader 实例，batch_size 设置每次加载的样本数量,其中shuffle表示是否对数据进行洗牌，通常训练时需要将数据打乱。</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">dataloader</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> DataLoader</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">dataset,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> batch_size=2,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> shuffle=True</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 打印加载的数据</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">for</span><span style="color:#B07D48;--shiki-dark:#BD976A"> epoch</span><span style="color:#1E754F;--shiki-dark:#4D9375"> in</span><span style="color:#B56959;--shiki-dark:#C98A7D"> range</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">1</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">    for</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> batch_idx, </span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">inputs,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> labels</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> in enumerate</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">dataloader</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">:</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">        print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">f</span><span style="color:#59873A;--shiki-dark:#80A665">'Batch {batch_idx + 1}:'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">        print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">f</span><span style="color:#59873A;--shiki-dark:#80A665">'Inputs: {inputs}'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">        print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">f</span><span style="color:#59873A;--shiki-dark:#80A665">'Labels: {labels}'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">Batch</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 1:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">Inputs:</span><span style="color:#B56959;--shiki-dark:#C98A7D"> tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#a65e2b;--shiki-dark:#d4976c">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">3., 4.</span><span style="color:#a65e2b;--shiki-dark:#d4976c">]</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#a65e2b;--shiki-dark:#d4976c">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1., 2.</span><span style="color:#a65e2b;--shiki-dark:#d4976c">]</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">Labels: tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 1</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">Batch 2:</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">Inputs: tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#a65e2b;--shiki-dark:#d4976c">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">7</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 8</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#a65e2b;--shiki-dark:#d4976c">]</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:#a65e2b;--shiki-dark:#d4976c">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">5</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 6</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#a65e2b;--shiki-dark:#d4976c">]</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">Labels: tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 1</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<h3 id="32对图像数据预处理和增强"><a class="anchor" href="#32对图像数据预处理和增强">#</a> 3.2对图像数据预处理和增强</h3>
<p>在pytorch中我们经常利用 <code>torchvision.transforms</code>模块对图像数据进行预处理和增强</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torchvision.transforms</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> transforms</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">from</span><span style="color:#B56959;--shiki-dark:#C98A7D"> PIL</span><span style="color:#B56959;--shiki-dark:#C98A7D"> import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> Image</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 定义数据预处理的流水线</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">transform</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> transforms.Compose</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.Resize</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#2F798A;--shiki-dark:#4C9A91">128</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 128</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">,  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 将图像调整为 128x128</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.ToTensor</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">,  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 将图像转换为张量</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.Normalize</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#B07D48;--shiki-dark:#BD976A">mean</span><span style="color:#AB5959;--shiki-dark:#CB7676">=</span><span style="color:#a13865;--shiki-dark:#d9739f">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">485</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">456</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">406</span><span style="color:#a13865;--shiki-dark:#d9739f">]</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> std</span><span style="color:#AB5959;--shiki-dark:#CB7676">=</span><span style="color:#a13865;--shiki-dark:#d9739f">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">229</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">224</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">225</span><span style="color:#a13865;--shiki-dark:#d9739f">]</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 标准化</span></span>
<span class="line"><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 加载图像</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">image</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> Image.open</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'image.jpg'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 应用预处理</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">image_tensor</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> transform</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">image</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">image_tensor.shape</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 输出张量的形状</span></span></code></pre>
<p>常见预处理方式：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>transforms.Resize(size)</code></td>
<td>调整图像大小为固定尺寸，例如 <code>(128, 128)</code></td>
</tr>
<tr>
<td><code>transforms.CenterCrop(size)</code></td>
<td>从中心裁剪固定大小</td>
</tr>
<tr>
<td><code>transforms.ToTensor()</code></td>
<td>将 PIL.Image 或 numpy.ndarray 转为 <code>[0, 1]</code> 的张量</td>
</tr>
<tr>
<td><code>transforms.Normalize(mean, std)</code></td>
<td>按通道标准化，常用于预训练模型输入要求</td>
</tr>
</tbody>
</table>
<p>常见数据增强方式：</p>
<table>
<thead>
<tr>
<th></th>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>transforms.RandomHorizontalFlip(p=0.5)</code></td>
<td>以概率 <code>p</code> 水平翻转图像</td>
</tr>
<tr>
<td><code>transforms.RandomVerticalFlip()</code></td>
<td>垂直翻转</td>
</tr>
<tr>
<td><code>transforms.RandomRotation(degrees)</code></td>
<td>随机旋转图像（角度范围）</td>
</tr>
<tr>
<td><code>transforms.ColorJitter()</code></td>
<td>改变图像的亮度、对比度、饱和度等</td>
</tr>
<tr>
<td><code>transforms.RandomResizedCrop(size)</code></td>
<td>随机裁剪后缩放到固定尺寸</td>
</tr>
<tr>
<td><code>transforms.RandomAffine(degrees, translate, scale, shear)</code></td>
<td>随机仿射变换</td>
</tr>
</tbody>
</table>
<p>如何对图像数据集进行加载呢，我们常利用<code>torchvision.datasets</code>对图像数据集进行加载</p>
<p>对于图像数据集，<code>torchvision.datasets</code> 提供了许多常见数据集（如 CIFAR-10、ImageNet、MNIST 等）以及用于加载图像数据的工具</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torchvision.datasets</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> datasets</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torchvision.transforms</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> transforms</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 定义预处理操作</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">transform</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> transforms.Compose</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.ToTensor</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">,</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.Normalize</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">5</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">5</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 对灰度图像进行标准化</span></span>
<span class="line"><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 下载并加载 MNIST 数据集</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">train_dataset</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> datasets.MNIST</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B07D48;--shiki-dark:#BD976A">root</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">./data</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> train</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">True,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> download</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">True,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> transform</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">transform</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">test_dataset</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> datasets.MNIST</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B07D48;--shiki-dark:#BD976A">root</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">./data</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> train</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">False,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> download</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">True,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> transform</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">transform</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建 DataLoader</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">train_loader</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> DataLoader</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">train_dataset,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> batch_size=64,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> shuffle=True</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">test_loader</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> DataLoader</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">test_dataset,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> batch_size=64,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> shuffle=False</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 迭代训练数据</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">for</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> inputs, labels in train_loader:</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">    print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">inputs.shape</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 每个批次的输入数据形状</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">    print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">labels.shape</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 每个批次的标签形状</span></span></code></pre>
<h3 id="33-pytorch-transforms"><a class="anchor" href="#33-pytorch-transforms">#</a> 3.3 pytorch---transforms</h3>
<table>
<thead>
<tr>
<th>类别</th>
<th>变换函数</th>
<th>描述说明</th>
<th>示例代码</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>预处理</strong></td>
<td><code>transforms.ToTensor()</code></td>
<td>将 PIL 图像或 NumPy 数组转换为张量，并将像素值归一化到 <code>[0, 1]</code></td>
<td><code>transforms.ToTensor()</code></td>
</tr>
<tr>
<td></td>
<td><code>transforms.Normalize(mean, std)</code></td>
<td>对图像张量进行标准化（零均值、单位方差）</td>
<td><code>transforms.Normalize(mean=[0.5], std=[0.5])</code></td>
</tr>
<tr>
<td></td>
<td><code>transforms.Resize(size)</code></td>
<td>将图像缩放到指定大小（宽、高）</td>
<td><code>transforms.Resize((128, 128))</code></td>
</tr>
<tr>
<td></td>
<td><code>transforms.CenterCrop(size)</code></td>
<td>从图像中心裁剪指定大小区域</td>
<td><code>transforms.CenterCrop(128)</code></td>
</tr>
<tr>
<td><strong>增强</strong></td>
<td><code>transforms.RandomHorizontalFlip(p)</code></td>
<td>以概率 <code>p</code> 随机水平翻转图像</td>
<td><code>transforms.RandomHorizontalFlip(p=0.5)</code></td>
</tr>
<tr>
<td></td>
<td><code>transforms.RandomRotation(degrees)</code></td>
<td>在 <code>[-degrees, +degrees]</code> 范围内随机旋转图像</td>
<td><code>transforms.RandomRotation(30)</code></td>
</tr>
<tr>
<td></td>
<td><code>transforms.ColorJitter(brightness, contrast, saturation, hue)</code></td>
<td>随机调整图像的亮度、对比度、饱和度、色调</td>
<td><code>transforms.ColorJitter(brightness=0.5, contrast=0.5)</code></td>
</tr>
<tr>
<td></td>
<td><code>transforms.RandomCrop(size)</code></td>
<td>随机从图像中裁剪出指定大小区域</td>
<td><code>transforms.RandomCrop(128)</code></td>
</tr>
<tr>
<td></td>
<td><code>transforms.RandomResizedCrop(size)</code></td>
<td>随机裁剪图像的一部分并缩放到给定大小</td>
<td><code>transforms.RandomResizedCrop(224)</code></td>
</tr>
<tr>
<td><strong>组合</strong></td>
<td><code>transforms.Compose([...])</code></td>
<td>将多个变换按顺序组合使用</td>
<td><code>transforms.Compose([ToTensor(), Normalize(...)])</code></td>
</tr>
</tbody>
</table>
<p>调用实例</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">transform</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> transforms.Compose</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.Resize</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#2F798A;--shiki-dark:#4C9A91">128</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 128</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">,</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.RandomHorizontalFlip</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#B07D48;--shiki-dark:#BD976A">p</span><span style="color:#AB5959;--shiki-dark:#CB7676">=</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">5</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">,</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.RandomRotation</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#B07D48;--shiki-dark:#BD976A">degrees</span><span style="color:#AB5959;--shiki-dark:#CB7676">=</span><span style="color:#2F798A;--shiki-dark:#4C9A91">15</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">,</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.ToTensor</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">,</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    transforms.Normalize</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#B07D48;--shiki-dark:#BD976A">mean</span><span style="color:#AB5959;--shiki-dark:#CB7676">=</span><span style="color:#a13865;--shiki-dark:#d9739f">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">5</span><span style="color:#a13865;--shiki-dark:#d9739f">]</span><span style="color:#AB5959;--shiki-dark:#CB7676">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> std</span><span style="color:#AB5959;--shiki-dark:#CB7676">=</span><span style="color:#a13865;--shiki-dark:#d9739f">[</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">.</span><span style="color:#2F798A;--shiki-dark:#4C9A91">5</span><span style="color:#a13865;--shiki-dark:#d9739f">]</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<hr>
<h2 id="四-线性回归"><a class="anchor" href="#四-线性回归">#</a> 四、线性回归</h2>
<p>首先什么是线性回归，可以说线性回归是一个没有隐藏层的前馈神经网络，非常基础的内容，对于一个简单的线性回归问题和模型通常可以表示成：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>a</mi><mn>1</mn></msub><mo>×</mo><mi>x</mi><mo>+</mo><msub><mi>a</mi><mn>2</mn></msub><mo>×</mo><mi>x</mi><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y=a_1 \times x+a_2 \times x+...+b
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">...</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></span></p>
<p>对数据集进行训练，对Y进行拟合</p>
<p>首先我们线先定义一个数据集</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 随机种子，确保每次运行结果一致</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">torch.manual_seed</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">42</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 生成训练数据</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">X</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.randn</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">100,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 2</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 100 个样本，每个样本 2 个特征</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">true_w</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.tensor</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">2.0, 3.0</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 假设真实权重</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">true_b</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 4.0</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 偏置项</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">Y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> X</span><span style="color:#B56959;--shiki-dark:#C98A7D"> @</span><span style="color:#B56959;--shiki-dark:#C98A7D"> true_w</span><span style="color:#B56959;--shiki-dark:#C98A7D"> +</span><span style="color:#B56959;--shiki-dark:#C98A7D"> true_b</span><span style="color:#B56959;--shiki-dark:#C98A7D"> +</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.randn</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">100</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A65E2B;--shiki-dark:#C99076"> *</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 0.1</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 加入一些噪声</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 打印部分数据</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">X[:5]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">Y[:5]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>之后我们再定义一个线性回归的模型类</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">class</span><span style="color:#B56959;--shiki-dark:#C98A7D"> LinearRegressionModel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">nn.Module</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        super</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">LinearRegressionModel,self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#59873A;--shiki-dark:#80A665">.__init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.linear</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">2,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 1</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> forward</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">        return</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>其中<code>super(LinearRegressionModel,self).__init__()</code>这点是关键：子类继承父类时，不自动调用父类的构造函数，你必须显式调用它。PyTorch 中所有自定义模型都要继承自 nn.Module。nn.Module 提供了很多核心功能。</p>
<p>之后我们实例化该模型，并定义后续需要的损失函数和优化器</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#B07D48;--shiki-dark:#BD976A">model</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#59873A;--shiki-dark:#80A665"> LinearRegressionModel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">criterion</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.MSELoss</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">optimizer</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> optim.SGD</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">model.parameters</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B07D48;--shiki-dark:#BD976A">lr</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">0.01</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>接下来便可以对模型进行训练了</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">num_epochs</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 100</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">for</span><span style="color:#B07D48;--shiki-dark:#BD976A"> epoch</span><span style="color:#1E754F;--shiki-dark:#4D9375"> in</span><span style="color:#B56959;--shiki-dark:#C98A7D"> range</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">num_epochs</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    model.train</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#B07D48;--shiki-dark:#BD976A">    predictions</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">model</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">X</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#B07D48;--shiki-dark:#BD976A">    loss</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">criterion</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">predictions.squeeze</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, Y</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 反向传播</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    optimizer.zero_grad</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 清空之前的梯度</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    loss.backward</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 计算梯度</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    optimizer.step</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 更新模型参数</span></span></code></pre>
<p>最后将数据可视化查看分析结果</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 查看训练后的权重和偏置</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">f</span><span style="color:#59873A;--shiki-dark:#80A665">'Predicted weight: {model.linear.weight.data.numpy()}'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">f</span><span style="color:#59873A;--shiki-dark:#80A665">'Predicted bias: {model.linear.bias.data.numpy()}'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 在新数据上做预测</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">with</span><span style="color:#B56959;--shiki-dark:#C98A7D"> torch.no_grad</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 评估时不需要计算梯度</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    predictions</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> model</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">X</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 可视化预测与实际值</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.scatter</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">X</span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#59873A;--shiki-dark:#80A665">:,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 0],</span><span style="color:#B56959;--shiki-dark:#C98A7D"> Y,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> color=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">blue</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> label=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">True values</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.scatter</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">X</span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#59873A;--shiki-dark:#80A665">:,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 0],</span><span style="color:#B56959;--shiki-dark:#C98A7D"> predictions,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> color=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">red</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> label=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Predictions</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.legend</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p><img loading="lazy" src="/images/pytorch/linearRgression.png" alt="ex4"></p>
<p>训练过程，随着loss减小，模型的权重和偏置将不断和true_w和true_b相接近</p>
<hr>
<h2 id="五-卷积神经网络"><a class="anchor" href="#五-卷积神经网络">#</a> 五、卷积神经网络</h2>
<p>是用于处理具有网格状拓扑结构数据(网格状结构是一种将数据点按照行列（二维坐标）方式排列的数据结构。每个点的邻居是它上下左右的节点，类似于棋盘、图像像素排列、或地理栅格。)</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">A11</span><span style="color:#B56959;--shiki-dark:#C98A7D">  A12</span><span style="color:#B56959;--shiki-dark:#C98A7D">  A13</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">A21</span><span style="color:#B56959;--shiki-dark:#C98A7D">  A22</span><span style="color:#B56959;--shiki-dark:#C98A7D">  A23</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">A31</span><span style="color:#B56959;--shiki-dark:#C98A7D">  A32</span><span style="color:#B56959;--shiki-dark:#C98A7D">  A33</span></span></code></pre>
<p>这是一张整个卷积神经网络过程的思维导图<br>
<img loading="lazy" src="/images/pytorch/CNN.png" alt="CNN"></p>
<p>对一些概念的解析：</p>
<ul>
<li>池化层：池化相当于把一个图的分辨率给降低，让图变小，减小需要处理的数据量同时不改变图的特征</li>
<li>卷积层: 是利用卷积核在图上进行特征提取，生成特征图像，如sobel算子就是提取图像边缘信息的卷积核</li>
<li>展平层：将多维的特征图转换为一维向量，以便输入到全连接层
<ul>
<li>在 CNN 的前面部分，通常包含多个卷积层（Conv2d）、池化层（MaxPool2d），这些操作处理的是 3D 的张量（形状一般是 [batch_size, channels, height, width]）。但全连接层（nn.Linear）只能接收二维的张量（形状 [batch_size, feature_dim]），所以必须先“展平”卷积输出。</li>
</ul>
</li>
<li>全连接层：类似于传统的神经网络层，用于将提取的特征映射到输出类别</li>
</ul>
<p>知道上面这些知识之后接下来便可以实现一个CNN	手写数字图像识别的实例了</p>
<p>定义一个简单的CNN模型</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">class</span><span style="color:#B56959;--shiki-dark:#C98A7D"> SimpleCNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">nn.Module</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        super</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">SimpleCNN,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#59873A;--shiki-dark:#80A665">.__init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 定义卷积层：输入1通道，输出32通道，卷积核大小3x3</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.conv1</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Conv2d</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 32,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> kernel_size=3,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> stride=1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> padding=</span><span style="color:#2F798A;--shiki-dark:#4C9A91">1</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 定义卷积层：输入32通道，输出64通道</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.conv2</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Conv2d</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">32,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 64,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> kernel_size=3,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> stride=1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> padding=</span><span style="color:#2F798A;--shiki-dark:#4C9A91">1</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 定义全连接层</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.fc1</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">64</span><span style="color:#A65E2B;--shiki-dark:#C99076"> *</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 7</span><span style="color:#A65E2B;--shiki-dark:#C99076"> *</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 7,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 128</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 输入大小 = 特征图大小 * 通道数</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.fc2</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">128,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 10</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 10 个类别</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> forward</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> F.relu</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self.conv1</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 第一层卷积 + ReLU</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> F.max_pool2d</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 2</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">     # 最大池化</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> F.relu</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self.conv2</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 第二层卷积 + ReLU</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> F.max_pool2d</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 2</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">     # 最大池化</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x.view</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">-1,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 64</span><span style="color:#A65E2B;--shiki-dark:#C99076"> *</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 7</span><span style="color:#A65E2B;--shiki-dark:#C99076"> *</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 7</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD"> # 展平操作</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> F.relu</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self.fc1</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 全连接层 + ReLU</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.fc2</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">            # 全连接层输出</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">        return</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建模型实例</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">model</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> SimpleCNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<hr>
<h2 id="六-循环神经网络"><a class="anchor" href="#六-循环神经网络">#</a> 六、循环神经网络</h2>
<h3 id="61理解循环rnn"><a class="anchor" href="#61理解循环rnn">#</a> 6.1理解循环RNN</h3>
<p>首先丢张RNN图方便理解什么是RNN</p>
<p><img loading="lazy" src="/images/pytorch/RNN.png" alt="RNN"></p>
<p>从上图可以非常直观的看，在 RNN 中，数据不仅沿着网络层级流动，还会在每个时间步骤上传播到当前的隐层状态，从而将之前的信息传递到下一个时间步骤。</p>
<p>于是我们可以可以得到如下两个式子</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_t=f(W_{hh}h_{t-1} +W_{xh}x_t+b_h)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hh</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub><msub><mi>h</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">y_t=W_{hy}h_t+b_y
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中:</p>
<ul>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{xh}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>:输入到隐藏状态的权重矩阵，用于将输入<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">X_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>转换为隐藏状态的一部分</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{hh}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hh</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>:隐藏状态到隐藏状态的权重矩阵，用于将前一时间步的隐藏状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">h_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>转换为当前时间步隐藏状态的一部分。</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{hy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>:隐藏状态到输出的权重矩阵，用于将隐藏状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>转换为输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">y_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p>
</li>
<li>
<p>f:激活函数(如 Tanh 或 ReLU)</p>
</li>
<li>
<p>隐藏状态 (ht,ht-1,....): 它在每个时间步存储有关序列的信息。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是当前时间步的隐藏状态，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">h_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>是前一个时间步的隐藏状态。</p>
</li>
</ul>
<h3 id="62rnn实际实现"><a class="anchor" href="#62rnn实际实现">#</a> 6.2RNN实际实现</h3>
<p>在pytorch内有几种RNN模块</p>
<ol>
<li>torch.nn.RNN：基本的RNN单元</li>
<li>torch.nn.LSTM：长短期记忆单元，能够学习长期依赖关系</li>
<li>torch.nn.GRU：门控循环单元，是LSTM的简化版本，但通常更容易训练</li>
</ol>
<p>如下是一个简单的RNN模型</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">class</span><span style="color:#B56959;--shiki-dark:#C98A7D"> SimpleRNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">nn.Module</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> __init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> input_size,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> hidden_size,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> output_size</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        super</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">SimpleRNN,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#59873A;--shiki-dark:#80A665">.__init__</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 定义 RNN 层</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.rnn</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.RNN</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">input_size,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> hidden_size,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> batch_first=True</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 定义全连接层</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        self.fc</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> nn.Linear</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">hidden_size,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> output_size</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    def</span><span style="color:#B56959;--shiki-dark:#C98A7D"> forward</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">self,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#B56959;--shiki-dark:#C98A7D">:</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # x: (batch_size, seq_len, input_size)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        out,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> _</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.rnn</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # out: (batch_size, seq_len, hidden_size)</span></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">        # 取序列最后一个时间步的输出作为模型的输出</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        out</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> out[:,</span><span style="color:#A65E2B;--shiki-dark:#C99076"> -1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> :]</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # (batch_size, hidden_size)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">        out</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> self.fc</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">out</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 全连接层</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">        return</span><span style="color:#B56959;--shiki-dark:#C98A7D"> out</span></span></code></pre>
<p>其中</p>
<table>
<thead>
<tr>
<th>维度名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>batch_size</code></td>
<td>一次喂给模型的本个数（用于加速训练）</td>
</tr>
<tr>
<td><code>seq_len</code></td>
<td>每个样本有多少个时间步（即序列长度）</td>
</tr>
<tr>
<td><code>input_size</code></td>
<td>每个时间步输入的特征维度（如词向量维度）</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="七-transformer架构"><a class="anchor" href="#七-transformer架构">#</a> 七、 Transformer架构</h2>
<h3 id="71-什么是transformer架构"><a class="anchor" href="#71-什么是transformer架构">#</a> 7.1 什么是transformer架构</h3>
<p>如下是一张论文中的解释transformer的图</p>
<p><img loading="lazy" src="/images/pytorch/transformer.jpg" alt=""></p>
<p>transformer架构就是利用注意力机制来获取序列之间联系的神经网络模型</p>
<h3 id="72-注意力机制"><a class="anchor" href="#72-注意力机制">#</a> 7.2 注意力机制</h3>
<p>可以理解为attention机制实质上就是权重的问题</p>
<p><img loading="lazy" src="/images/pytorch/attention.png" alt="attention"></p>
<p><img loading="lazy" src="/images/pytorch/self-attention.png" alt="self-attention"></p>
<h3 id="73-transformer架构的实现机理"><a class="anchor" href="#73-transformer架构的实现机理">#</a> 7.3 transformer架构的实现机理</h3>
<p><img loading="lazy" src="/images/pytorch/transformer1.png" alt=""></p>
<p><img loading="lazy" src="/images/pytorch/transformer2.png" alt=""></p>
<ul>
<li>
<p>Position Encoding:给每个词一个位置编码，表示该词在句子中的位置信息</p>
</li>
<li>
<p>Multi-Head Attension:对不同模块间产生的注意力机制</p>
</li>
</ul>
<hr>
<h2 id="八-torch内常见函数"><a class="anchor" href="#八-torch内常见函数">#</a> 八、torch内常见函数</h2>
<p>张量类型检查和配置：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.is_tensor(obj)</code></td>
<td>检查是否为张量</td>
</tr>
<tr>
<td><code>torch.is_storage(obj)</code></td>
<td>检查是否为存储对象</td>
</tr>
<tr>
<td><code>torch.is_complex(input)</code></td>
<td>是否为复数类型</td>
</tr>
<tr>
<td><code>torch.is_conj(input)</code></td>
<td>是否为共轭张量</td>
</tr>
<tr>
<td><code>torch.is_floating_point(input)</code></td>
<td>是否为浮点类型</td>
</tr>
<tr>
<td><code>torch.is_nonzero(input)</code></td>
<td>是否为非零单元素张量</td>
</tr>
<tr>
<td><code>torch.set_default_dtype(d)</code></td>
<td>设置默认浮点数据类型</td>
</tr>
<tr>
<td><code>torch.get_default_dtype()</code></td>
<td>获取当前默认浮点数据类型</td>
</tr>
<tr>
<td><code>torch.set_default_device(device)</code></td>
<td>设置默认张量设备</td>
</tr>
<tr>
<td><code>torch.get_default_device()</code></td>
<td>获取默认张量设备</td>
</tr>
<tr>
<td><code>torch.numel(input)</code></td>
<td>获取元素总数</td>
</tr>
</tbody>
</table>
<p>Tensor 创建：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.tensor(data)</code></td>
<td>从数据创建张量</td>
</tr>
<tr>
<td><code>torch.as_tensor(data)</code></td>
<td>转换为张量，共享数据</td>
</tr>
<tr>
<td><code>torch.from_numpy(ndarray)</code></td>
<td>从 NumPy 创建张量，共享数据</td>
</tr>
<tr>
<td><code>torch.zeros(size)</code></td>
<td>创建全零张量</td>
</tr>
<tr>
<td><code>torch.ones(size)</code></td>
<td>创建全一张量</td>
</tr>
<tr>
<td><code>torch.empty(size)</code></td>
<td>创建未初始化张量</td>
</tr>
<tr>
<td><code>torch.arange(start, end, step)</code></td>
<td>创建等差序列张量</td>
</tr>
<tr>
<td><code>torch.linspace(start, end, steps)</code></td>
<td>创建线性间隔张量</td>
</tr>
<tr>
<td><code>torch.logspace(start, end, steps, base)</code></td>
<td>创建对数间隔张量</td>
</tr>
<tr>
<td><code>torch.eye(n, m)</code></td>
<td>创建单位矩阵</td>
</tr>
<tr>
<td><code>torch.full(size, fill_value)</code></td>
<td>创建填充指定值的张量</td>
</tr>
<tr>
<td><code>torch.rand(size)</code></td>
<td>均匀分布随机张量</td>
</tr>
<tr>
<td><code>torch.randn(size)</code></td>
<td>标准正态分布张量</td>
</tr>
<tr>
<td><code>torch.randint(low, high, size)</code></td>
<td>整数随机张量</td>
</tr>
<tr>
<td><code>torch.randperm(n)</code></td>
<td>0 到 n-1 的随机排列</td>
</tr>
</tbody>
</table>
<p>Tensor 操作：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.cat(tensors, dim)</code></td>
<td>沿指定维度拼接张量</td>
</tr>
<tr>
<td><code>torch.stack(tensors, dim)</code></td>
<td>沿新维度堆叠张量</td>
</tr>
<tr>
<td><code>torch.split(tensor, split_size, dim)</code></td>
<td>按大小分割张量</td>
</tr>
<tr>
<td><code>torch.chunk(tensor, chunks, dim)</code></td>
<td>按块分割张量</td>
</tr>
<tr>
<td><code>torch.reshape(input, shape)</code></td>
<td>改变形状</td>
</tr>
<tr>
<td><code>torch.transpose(input, dim0, dim1)</code></td>
<td>转置两个维度</td>
</tr>
<tr>
<td><code>torch.squeeze(input, dim)</code></td>
<td>去除 1 维度</td>
</tr>
<tr>
<td><code>torch.unsqueeze(input, dim)</code></td>
<td>添加 1 维度</td>
</tr>
<tr>
<td><code>torch.expand(input, size)</code></td>
<td>扩展维度</td>
</tr>
<tr>
<td><code>torch.narrow(input, dim, start, length)</code></td>
<td>张量切片</td>
</tr>
<tr>
<td><code>torch.permute(input, dims)</code></td>
<td>维度重排</td>
</tr>
<tr>
<td><code>torch.masked_select(input, mask)</code></td>
<td>布尔掩码选择</td>
</tr>
<tr>
<td><code>torch.index_select(input, dim, index)</code></td>
<td>索引选择元素</td>
</tr>
<tr>
<td><code>torch.gather(input, dim, index)</code></td>
<td>按索引收集数据</td>
</tr>
<tr>
<td><code>torch.scatter(input, dim, index, src)</code></td>
<td>按索引写入数据</td>
</tr>
<tr>
<td><code>torch.nonzero(input)</code></td>
<td>获取非零索引</td>
</tr>
</tbody>
</table>
<p>数学运算：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.add(input, other)</code></td>
<td>加法</td>
</tr>
<tr>
<td><code>torch.sub(input, other)</code></td>
<td>减法</td>
</tr>
<tr>
<td><code>torch.mul(input, other)</code></td>
<td>乘法</td>
</tr>
<tr>
<td><code>torch.div(input, other)</code></td>
<td>除法</td>
</tr>
<tr>
<td><code>torch.pow(input, exponent)</code></td>
<td>幂运算</td>
</tr>
<tr>
<td><code>torch.sqrt(input)</code></td>
<td>平方根</td>
</tr>
<tr>
<td><code>torch.exp(input)</code></td>
<td>指数函数</td>
</tr>
<tr>
<td><code>torch.log(input)</code></td>
<td>自然对数</td>
</tr>
<tr>
<td><code>torch.sum(input, dim)</code></td>
<td>求和</td>
</tr>
<tr>
<td><code>torch.mean(input, dim)</code></td>
<td>求均值</td>
</tr>
<tr>
<td><code>torch.max(input, dim)</code></td>
<td>最大值</td>
</tr>
<tr>
<td><code>torch.min(input, dim)</code></td>
<td>最小值</td>
</tr>
<tr>
<td><code>torch.abs(input)</code></td>
<td>绝对值</td>
</tr>
<tr>
<td><code>torch.clamp(input, min, max)</code></td>
<td>限制范围</td>
</tr>
<tr>
<td><code>torch.round(input)</code></td>
<td>四舍五入</td>
</tr>
<tr>
<td><code>torch.floor(input)</code></td>
<td>向下取整</td>
</tr>
<tr>
<td><code>torch.ceil(input)</code></td>
<td>向上取整</td>
</tr>
</tbody>
</table>
<p>随机数生成：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.manual_seed(seed)</code></td>
<td>设置随机种子</td>
</tr>
<tr>
<td><code>torch.initial_seed()</code></td>
<td>获取当前种子</td>
</tr>
<tr>
<td><code>torch.rand(size)</code></td>
<td>均匀分布张量</td>
</tr>
<tr>
<td><code>torch.randn(size)</code></td>
<td>正态分布张量</td>
</tr>
<tr>
<td><code>torch.randint(low, high, size)</code></td>
<td>整数随机张量</td>
</tr>
<tr>
<td><code>torch.randperm(n)</code></td>
<td>随机排列序列</td>
</tr>
</tbody>
</table>
<p>线性代数：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.dot(input, other)</code></td>
<td>向量点积</td>
</tr>
<tr>
<td><code>torch.mm(input, mat2)</code></td>
<td>矩阵乘法</td>
</tr>
<tr>
<td><code>torch.bmm(input, mat2)</code></td>
<td>批量矩阵乘法</td>
</tr>
<tr>
<td><code>torch.eig(input)</code></td>
<td>特征值和特征向量</td>
</tr>
<tr>
<td><code>torch.svd(input)</code></td>
<td>奇异值分解</td>
</tr>
<tr>
<td><code>torch.inverse(input)</code></td>
<td>矩阵逆</td>
</tr>
<tr>
<td><code>torch.det(input)</code></td>
<td>行列式</td>
</tr>
<tr>
<td><code>torch.trace(input)</code></td>
<td>矩阵迹</td>
</tr>
</tbody>
</table>
<p>设备管理：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.cuda.is_available()</code></td>
<td>是否支持 CUDA</td>
</tr>
<tr>
<td><code>torch.device(device)</code></td>
<td>创建设备对象</td>
</tr>
<tr>
<td><code>tensor.to(device)</code></td>
<td>张量迁移设备</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="番外一-pyplot"><a class="anchor" href="#番外一-pyplot">#</a> 番外一、pyplot</h2>
<h3 id="1基本绘图流程"><a class="anchor" href="#1基本绘图流程">#</a> 1.基本绘图流程</h3>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 1. 准备数据</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, </span><span style="color:#B56959;--shiki-dark:#C98A7D">2,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 3,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 4,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 5]</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, </span><span style="color:#B56959;--shiki-dark:#C98A7D">4,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 9,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 16,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 25]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 2. 绘图</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.plot</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> y</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 3. 添加标题和标签</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">"折线图示例"</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.xlabel</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">"X轴"</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.ylabel</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">"Y轴"</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 4. 显示图像</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"></span></code></pre>
<ol>
<li>准备好y关于x函数关系的数据</li>
<li>利用plot函数进行图像绘制，并对相关属性进行定义</li>
<li>对轴进行处理</li>
</ol>
<p>相关参数ex：</p>
<p><img loading="lazy" src="/images/pytorch/pyplot-fmt.png" alt="fmt"></p>
<table>
<thead>
<tr>
<th><code>marker</code> 值</th>
<th>含义</th>
<th>显示效果</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>'o'</code></td>
<td>圆圈</td>
<td>●</td>
</tr>
<tr>
<td><code>'s'</code></td>
<td>方形</td>
<td>■</td>
</tr>
<tr>
<td><code>'^'</code></td>
<td>上三角</td>
<td>▲</td>
</tr>
<tr>
<td><code>'v'</code></td>
<td>下三角</td>
<td>▼</td>
</tr>
<tr>
<td><code>'&gt;'</code></td>
<td>右三角</td>
<td>▶</td>
</tr>
<tr>
<td><code>'&lt;'</code></td>
<td>左三角</td>
<td>◀</td>
</tr>
<tr>
<td><code>'x'</code></td>
<td>十字叉</td>
<td>✕</td>
</tr>
<tr>
<td><code>'+'</code></td>
<td>加号</td>
<td>＋</td>
</tr>
<tr>
<td><code>'*'</code></td>
<td>星号</td>
<td>★</td>
</tr>
<tr>
<td><code>'.'</code></td>
<td>点</td>
<td>·</td>
</tr>
<tr>
<td><code>'D'</code></td>
<td>菱形</td>
<td>◆</td>
</tr>
<tr>
<td><code>'p'</code></td>
<td>五边形</td>
<td>⬟</td>
</tr>
<tr>
<td><code>'h'</code></td>
<td>六边形1</td>
<td>⬢</td>
</tr>
<tr>
<td><code>'H'</code></td>
<td>六边形2</td>
<td>⬣</td>
</tr>
<tr>
<td><code>None</code></td>
<td>无标记</td>
<td>无</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th><code>linestyle</code> 值</th>
<th>含义</th>
<th>示例样式</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>'-'</code></td>
<td>实线</td>
<td>──────────────</td>
</tr>
<tr>
<td><code>'--'</code></td>
<td>虚线</td>
<td>– – – – – – – –</td>
</tr>
<tr>
<td><code>'-.'</code></td>
<td>点划线</td>
<td>– · – · – · – ·</td>
</tr>
<tr>
<td><code>':'</code></td>
<td>点线</td>
<td>··············</td>
</tr>
<tr>
<td><code>''</code> or <code>None</code></td>
<td>无线条</td>
<td>无</td>
</tr>
</tbody>
</table>
<h3 id="2网格线"><a class="anchor" href="#2网格线">#</a> 2.网格线</h3>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, 2, 3, 4</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, 4, 9, 16</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"RUNOOB grid() Test"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.xlabel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"x - label"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.ylabel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"y - label"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.plot</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> y</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.grid</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">color</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> '</span><span style="color:#B56959;--shiki-dark:#C98A7D">r</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> linestyle</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> '</span><span style="color:#B56959;--shiki-dark:#C98A7D">--</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> linewidth</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 0.5</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p><img loading="lazy" src="/images/pytorch/ex1.png" alt="ex1"></p>
<p>grid内还有axis属性，若设置axis=x则网格线就在y方向上出现</p>
<h3 id="3绘制多图"><a class="anchor" href="#3绘制多图">#</a> 3.绘制多图</h3>
<p>基础的用subplot方法绘图：</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">#plot 1:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">xpoints</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">0, 6</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">ypoints</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">0, 100</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.subplot</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 2,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 1</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.plot</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">xpoints,ypoints</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"plot 1"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD">#plot 2:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, 2, 3, 4</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, 4, 9, 16</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.subplot</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 2,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 2</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.plot</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,y</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"plot 2"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.suptitle</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"RUNOOB subplot Test"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p><img loading="lazy" src="/images/pytorch/ex2.png" alt="ex2"></p>
<p>其中suplot(a,b,c)这三个参数分别说明，有a行b列个图，当前该图排在第c位</p>
<h3 id="3散点柱形直方图和饼图s"><a class="anchor" href="#3散点柱形直方图和饼图s">#</a> 3.散点，柱形,直方图和饼图s</h3>
<h4 id="1散点图"><a class="anchor" href="#1散点图">#</a> 1.散点图</h4>
<p>我们可以使用 pyplot 中的 scatter() 方法来绘制散点图。</p>
<p>基础调用方式：</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, 2, 3, 4, 5, 6, 7, 8</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">1, 4, 9, 16, 7, 11, 23, 18</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.scatter</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> y</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>scatter() 方法语法格式如下：</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">matplotlib.pyplot.scatter</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> y,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> s=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> c=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> marker=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> cmap=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> norm=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> vmin=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> vmax=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> alpha=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> linewidths=None,</span><span style="color:#A65E2B;--shiki-dark:#C99076"> *</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> edgecolors=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plotnonfinite=False,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> data=None,</span><span style="color:#A65E2B;--shiki-dark:#C99076"> **</span><span style="color:#B56959;--shiki-dark:#C98A7D">kwargs</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>类型</th>
<th>作用说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td>array-like</td>
<td>每个点的 x 坐标（必须）</td>
</tr>
<tr>
<td><code>y</code></td>
<td>array-like</td>
<td>每个点的 y 坐标（必须）</td>
</tr>
<tr>
<td><code>s</code></td>
<td>float 或 array</td>
<td>点的<strong>大小</strong>，默认为 20；可设置为数组使每个点大小不同</td>
</tr>
<tr>
<td><code>c</code></td>
<td>color 或 array</td>
<td>点的<strong>颜色</strong>，可以是字符串如 <code>'red'</code>，或数组映射 colormap</td>
</tr>
<tr>
<td><code>marker</code></td>
<td>str</td>
<td>点的<strong>形状</strong>，如 <code>'o'</code> 圆点、<code>'^'</code> 三角等</td>
</tr>
<tr>
<td><code>cmap</code></td>
<td>colormap</td>
<td>用于将 <code>c</code> 数组映射为颜色的<strong>颜色映射表</strong>（如 <code>plt.cm.Blues</code>）</td>
</tr>
<tr>
<td><code>norm</code></td>
<td>Normalize 实例</td>
<td>自定义颜色归一化方式，配合 <code>cmap</code> 使用</td>
</tr>
<tr>
<td><code>vmin</code></td>
<td>float</td>
<td><code>cmap</code> 的最小值（可控制颜色范围）</td>
</tr>
<tr>
<td><code>vmax</code></td>
<td>float</td>
<td><code>cmap</code> 的最大值（同上）</td>
</tr>
<tr>
<td><code>alpha</code></td>
<td>float [0, 1]</td>
<td>点的<strong>透明度</strong>，1为不透明，0为完全透明</td>
</tr>
<tr>
<td><code>linewidths</code></td>
<td>float 或 array</td>
<td>点的边框线宽</td>
</tr>
<tr>
<td><code>edgecolors</code></td>
<td face,="" none="">color or</td>
<td>点的边框颜色，可设为 <code>'face'</code>（和点一样）或 <code>'none'</code>（无边框）</td>
</tr>
<tr>
<td><code>plotnonfinite</code></td>
<td>bool</td>
<td>是否绘制 NaN 或 Inf 值，默认 False</td>
</tr>
<tr>
<td><code>data</code></td>
<td>dict 或 DataFrame</td>
<td>支持使用 <code>data["x"]</code> 方式传参</td>
</tr>
<tr>
<td><code>**kwargs</code></td>
<td></td>
<td>传递给底层 <code>PathCollection</code> 的其他参数</td>
</tr>
</tbody>
</table>
<h4 id="2柱形图"><a class="anchor" href="#2柱形图">#</a> 2.柱形图</h4>
<p>基础绘制方式：</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">Runoob-1</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">Runoob-2</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">Runoob-3</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">C-RUNOOB</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">12, 22, 6, 18</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.bar</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,y</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td>array-like</td>
<td>每个条形的 x 坐标（分类变量索引或标签）</td>
</tr>
<tr>
<td><code>height</code></td>
<td>array-like</td>
<td>每个条形的高度</td>
</tr>
<tr>
<td><code>width</code></td>
<td>float 或 array</td>
<td>每个条形的宽度（默认 <code>0.8</code>）</td>
</tr>
<tr>
<td><code>bottom</code></td>
<td>float 或 array</td>
<td>每个条形的底部起始位置（默认是 <code>0</code>，用于堆叠）</td>
</tr>
<tr>
<td><code>align</code></td>
<td><code>'center'</code> or <code>'edge'</code></td>
<td>条形对齐方式，默认为 <code>'center'</code></td>
</tr>
<tr>
<td><code>color</code></td>
<td>颜色 或数组</td>
<td>条形颜色（可为字符串或 RGB 值）</td>
</tr>
<tr>
<td><code>edgecolor</code></td>
<td>颜色或数组</td>
<td>条形边框颜色</td>
</tr>
<tr>
<td><code>linewidth</code></td>
<td>float</td>
<td>条形边框宽度</td>
</tr>
<tr>
<td><code>tick_label</code></td>
<td>list</td>
<td>设置 x 轴刻度标签（如分类名称）</td>
</tr>
<tr>
<td><code>xerr</code>, <code>yerr</code></td>
<td>数组或标量</td>
<td>设置 x/y 方向的误差条（用于误差可视化）</td>
</tr>
<tr>
<td><code>ecolor</code></td>
<td>颜色</td>
<td>误差条的颜色</td>
</tr>
<tr>
<td><code>capsize</code></td>
<td>float</td>
<td>误差条末端横线的长度</td>
</tr>
<tr>
<td><code>label</code></td>
<td>str</td>
<td>设置用于图例的标签名</td>
</tr>
<tr>
<td><code>alpha</code></td>
<td>float</td>
<td>设置透明度（0~1）</td>
</tr>
</tbody>
</table>
<h4 id="3饼图"><a class="anchor" href="#3饼图">#</a> 3.饼图</h4>
<p>基础绘制方式</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">y</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.array</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">35, 25, 25, 15</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.pie</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">y</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td>list 或 array</td>
<td>各个扇区的数值（自动归一化为比例）</td>
</tr>
<tr>
<td><code>labels</code></td>
<td>list[str]</td>
<td>每个扇区的标签（显示在图上）</td>
</tr>
<tr>
<td><code>explode</code></td>
<td>list[float]</td>
<td>控制每个扇区“弹出”的距离（例如 <code>[0, 0.1, 0, 0.2]</code>）</td>
</tr>
<tr>
<td><code>colors</code></td>
<td>list[str]</td>
<td>扇区的颜色序列</td>
</tr>
<tr>
<td><code>autopct</code></td>
<td>str 或函数</td>
<td>自动显示百分比格式（如 <code>"%.1f%%"</code>）</td>
</tr>
<tr>
<td><code>pctdistance</code></td>
<td>float</td>
<td>百分比文本距离圆心的比例（默认 <code>0.6</code>）</td>
</tr>
<tr>
<td><code>labeldistance</code></td>
<td>float</td>
<td>标签文本距离圆心的比例（默认 <code>1.1</code>）</td>
</tr>
<tr>
<td><code>shadow</code></td>
<td>bool</td>
<td>是否显示阴影（立体效果）</td>
</tr>
<tr>
<td><code>startangle</code></td>
<td>float</td>
<td>起始角度（默认是 0，通常设为 90 更美观）</td>
</tr>
<tr>
<td><code>radius</code></td>
<td>float</td>
<td>饼图的半径（默认是 1）</td>
</tr>
<tr>
<td><code>counterclock</code></td>
<td>bool</td>
<td>是否逆时针绘图（默认是 <code>True</code>）</td>
</tr>
<tr>
<td><code>wedgeprops</code></td>
<td>dict</td>
<td>控制扇区样式，如边框：<code>{'edgecolor': 'black'}</code></td>
</tr>
<tr>
<td><code>textprops</code></td>
<td>dict</td>
<td>设置文本样式，如字体大小、颜色</td>
</tr>
<tr>
<td><code>center</code></td>
<td>(float, float)</td>
<td>饼图的中心坐标（默认 <code>(0, 0)</code>）</td>
</tr>
<tr>
<td><code>frame</code></td>
<td>bool</td>
<td>是否画图框（默认 <code>False</code>）</td>
</tr>
<tr>
<td><code>rotatelabels</code></td>
<td>bool</td>
<td>是否旋转标签使其与扇区对齐（默认 <code>False</code>）</td>
</tr>
<tr>
<td><code>normalize</code></td>
<td>bool</td>
<td>是否归一化数据为比例（Matplotlib 3.4+）</td>
</tr>
</tbody>
</table>
<h4 id="4直方图"><a class="anchor" href="#4直方图">#</a> 4.直方图</h4>
<p>基本绘制方式:</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 生成一组随机数据</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.random.randn</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">1000</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 绘制直方图</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.hist</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">data,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> bins=30,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> color=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">skyblue</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> alpha=</span><span style="color:#2F798A;--shiki-dark:#4C9A91">0.8</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 设置图表属性</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'RUNOOB hist() Test'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.xlabel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'Value'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.ylabel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'Frequency'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 显示图表</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">matplotlib.pyplot.hist</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> bins=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> range=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> density=False,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> weights=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> cumulative=False,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> bottom=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> histtype=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">bar</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> align=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">mid</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> orientation=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">vertical</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> rwidth=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> log=False,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> color=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> label=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> stacked=False,</span><span style="color:#A65E2B;--shiki-dark:#C99076"> **</span><span style="color:#B56959;--shiki-dark:#C98A7D">kwargs</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x</code></td>
<td>array-like</td>
<td>要绘制直方图的数据</td>
</tr>
<tr>
<td><code>bins</code></td>
<td>int 或序列</td>
<td>直方图的柱数或自定义的分箱边界（如 <code>bins=10</code> 或 <code>[0,1,2,3]</code>）</td>
</tr>
<tr>
<td><code>range</code></td>
<td>tuple(min, max)</td>
<td>设置数据范围，仅包含此范围内的值</td>
</tr>
<tr>
<td><code>density</code></td>
<td>bool</td>
<td>是否显示为<strong>概率密度</strong>（归一化面积为 1）</td>
</tr>
<tr>
<td><code>weights</code></td>
<td>array-like</td>
<td>给每个样本指定权重</td>
</tr>
<tr>
<td><code>cumulative</code></td>
<td>bool</td>
<td>是否绘制累计直方图</td>
</tr>
<tr>
<td><code>bottom</code></td>
<td>float 或 array</td>
<td>每个柱子的底部起点位置（默认从 0 开始）</td>
</tr>
<tr>
<td><code>histtype</code></td>
<td>str</td>
<td>直方图类型，常用有：&lt;br&gt;<code>'bar'</code>（默认，填充柱状图）&lt;br&gt;<code>'barstacked'</code>（堆叠柱状图）&lt;br&gt;<code>'step'</code>（不填充，边框）&lt;br&gt;<code>'stepfilled'</code>（填充阶梯）</td>
</tr>
<tr>
<td><code>align</code></td>
<td left,="" mid,="" right=""></td>
<td>柱子相对于 bin 边界的对齐方式</td>
</tr>
<tr>
<td><code>orientation</code></td>
<td vertical,="" horizontal=""></td>
<td>垂直 or 水平直方图</td>
</tr>
<tr>
<td><code>rwidth</code></td>
<td>float（0~1）</td>
<td>柱宽占 bin 宽度的比例（例如 0.8）</td>
</tr>
<tr>
<td><code>log</code></td>
<td>bool</td>
<td>y 轴是否使用对数刻度</td>
</tr>
<tr>
<td><code>color</code></td>
<td>str 或 list</td>
<td>设置柱子的颜色</td>
</tr>
<tr>
<td><code>label</code></td>
<td>str</td>
<td>图例标签</td>
</tr>
<tr>
<td><code>stacked</code></td>
<td>bool</td>
<td>是否堆叠多组数据</td>
</tr>
<tr>
<td><code>**kwargs</code></td>
<td>-</td>
<td>其他传入 <code>patches</code> 的参数，如透明度 <code>alpha</code>、边框 <code>edgecolor</code> 等</td>
</tr>
</tbody>
</table>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 生成三组随机数据</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">data1</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.random.normal</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">0,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 1,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 1000</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">data2</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.random.normal</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">2,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 1,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 1000</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">data3</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.random.normal</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">-2,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 1,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 1000</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 绘制直方图</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.hist</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">data1,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> bins=30,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> alpha=0.5,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> label=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Data 1</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.hist</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">data2,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> bins=30,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> alpha=0.5,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> label=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Data 2</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.hist</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">data3,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> bins=30,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> alpha=0.5,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> label=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Data 3</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 设置图表属性</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'RUNOOB hist() TEST'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.xlabel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'Value'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.ylabel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'Frequency'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.legend</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 显示图表</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>以上实例中我们生成了三组不同的随机数据，并使用 hist() 函数绘制了它们的直方图。通过设置不同的均值和标准差，我们可以生成具有不同分布特征的随机数据。</p>
<p>我们设置了 bins 参数为 30，这意味着将数据范围分成 30 个等宽的区间，然后统计每个区间内数据的频数。</p>
<p>我们设置了 alpha 参数为 0.5，这意味着每个直方图的颜色透明度为 50%。<br>
我们使用 label 参数设置了每个直方图的标签，以便在图例中显示。</p>
<p>然后使用 legend() 函数显示图例。最后，我们使用 title()、xlabel() 和 ylabel() 函数设置了图表的标题和坐标轴标签。</p>
<p>显示结果如下：</p>
<p><img loading="lazy" src="/images/pytorch/ex3.png" alt="ex3"></p>
<h3 id="4imshowimsaveimread"><a class="anchor" href="#4imshowimsaveimread">#</a> 4.imshow,imsave,imread</h3>
<p>imshow用于图像显示</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 创建一个 10x10 随机图像</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">img</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.random.rand</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">10,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 10</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.imshow</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">img,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> cmap=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">viridis</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> interpolation=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">nearest</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.colorbar</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"随机图像"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>X</code></td>
<td>输入图像（2D/3D NumPy 数组）</td>
</tr>
<tr>
<td><code>cmap</code></td>
<td>颜色映射（如 <code>'gray'</code>, <code>'viridis'</code>, <code>'hot'</code> 等）</td>
</tr>
<tr>
<td><code>interpolation</code></td>
<td>插值方法（如 <code>'nearest'</code>, <code>'bilinear'</code>，用于放缩）</td>
</tr>
<tr>
<td><code>vmin</code>, <code>vmax</code></td>
<td>用于归一化图像值范围（像素值映射到颜色）</td>
</tr>
<tr>
<td><code>alpha</code></td>
<td>透明度（0 到 1）</td>
</tr>
<tr>
<td><code>extent</code></td>
<td>设置坐标轴范围，例如 <code>[xmin, xmax, ymin, ymax]</code></td>
</tr>
<tr>
<td><code>origin</code></td>
<td><code>'upper'</code> 或 <code>'lower'</code>，设置图像原点方向</td>
</tr>
</tbody>
</table>
<p>imread用于读取图像</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">img</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt.imread</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"cat.jpg"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">img.shape</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 例如 (400, 600, 3)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.imshow</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">img</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.axis</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">'off'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.title</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"猫猫图像"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.show</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>imsave用于保存图像</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> matplotlib.pyplot</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> plt</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> numpy</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 保存一张随机图像</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">img</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> np.random.rand</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">100,</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 100</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">plt.imsave</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">"random_image.png"</span><span style="color:#59873A;--shiki-dark:#80A665">,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> img,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> cmap=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">gray</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>fname</code></td>
<td>保存文件路径（字符串）</td>
</tr>
<tr>
<td><code>arr</code></td>
<td>NumPy 图像数组</td>
</tr>
<tr>
<td><code>cmap</code></td>
<td>映射颜色表（灰度图需要）</td>
</tr>
<tr>
<td><code>format</code></td>
<td>可选强制保存格式</td>
</tr>
<tr>
<td><code>vmin</code>, <code>vmax</code></td>
<td>映射像素值范围（归一化）</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="番外二-数据处理篇"><a class="anchor" href="#番外二-数据处理篇">#</a> 番外二、数据处理篇</h2>
<h3 id="pandas操作外部数据"><a class="anchor" href="#pandas操作外部数据">#</a> Pandas操作外部数据</h3>
<ol>
<li>读取 CSV 文件：<code>pd.read_csv()</code></li>
</ol>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-python"><span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">import</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> pandas </span><span style="color:#1E754F;--shiki-dark:#4D9375">as</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> pd</span></span>
<span class="line"></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">df </span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> pd</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">read_csv</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">data.csv</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>sep</code></td>
<td>分隔符，默认<code>,</code>，可以设为<code>\t</code></td>
</tr>
<tr>
<td><code>header</code></td>
<td>指定哪一行为列名</td>
</tr>
<tr>
<td><code>names</code></td>
<td>自定义列名</td>
</tr>
<tr>
<td><code>index_col</code></td>
<td>指定哪列作为索引</td>
</tr>
<tr>
<td><code>usecols</code></td>
<td>读取指定列</td>
</tr>
<tr>
<td><code>encoding</code></td>
<td>编码，避免中文乱码用<code>utf-8-sig</code> 或 <code>gbk</code></td>
</tr>
</tbody>
</table>
<ol start="2">
<li>写入 CSV 文件：<code>df.to_csv()</code></li>
</ol>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-python"><span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">df</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">to_csv</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">output.csv</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> index</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#1E754F;--shiki-dark:#4D9375">False</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> encoding</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">utf-8-sig</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<hr>
<ol start="3">
<li>读取 Excel 文件：<code>pd.read_excel()</code></li>
</ol>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-python"><span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">df </span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> pd</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">read_excel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">data.xlsx</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> sheet_name</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">Sheet1</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>sheet_name</code></td>
<td>工作表名称或索引</td>
</tr>
<tr>
<td><code>usecols</code></td>
<td>指定读取列</td>
</tr>
<tr>
<td><code>index_col</code></td>
<td>设置索引列</td>
</tr>
</tbody>
</table>
<ol start="4">
<li>写入 Excel 文件：<code>df.to_excel()</code></li>
</ol>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-python"><span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">df</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">to_excel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">output.xlsx</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> sheet_name</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">结果</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> index</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#1E754F;--shiki-dark:#4D9375">False</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<ol start="5">
<li>多个 sheet 写入</li>
</ol>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-python"><span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">with</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> pd</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">ExcelWriter</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">multi.xlsx</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#1E754F;--shiki-dark:#4D9375"> as</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> writer</span><span style="color:#999999;--shiki-dark:#666666">:</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    df1</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">to_excel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">writer</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> sheet_name</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">Sheet1</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">    df2</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">to_excel</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">writer</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> sheet_name</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">Sheet2</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<hr>
<ol start="6">
<li>读取 JSON 文件：<code>pd.read_json()</code></li>
</ol>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-python"><span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">df </span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> pd</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">read_json</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">data.json</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<p>JSON 格式要求：通常是数组对象结构，如：</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-json"><span class="line"><span style="color:#2993a3;--shiki-dark:#5eaab5">[</span></span>
<span class="line"><span style="color:#999999;--shiki-dark:#666666">  </span><span style="color:#1e754f;--shiki-dark:#4d9375">{</span><span style="color:#99841877;--shiki-dark:#B8A96577">"</span><span style="color:#998418;--shiki-dark:#B8A965">name</span><span style="color:#99841877;--shiki-dark:#B8A96577">"</span><span style="color:#999999;--shiki-dark:#666666">:</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> "</span><span style="color:#B56959;--shiki-dark:#C98A7D">Alice</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#99841877;--shiki-dark:#B8A96577"> "</span><span style="color:#998418;--shiki-dark:#B8A965">age</span><span style="color:#99841877;--shiki-dark:#B8A96577">"</span><span style="color:#999999;--shiki-dark:#666666">:</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 25</span><span style="color:#1e754f;--shiki-dark:#4d9375">}</span><span style="color:#999999;--shiki-dark:#666666">,</span></span>
<span class="line"><span style="color:#999999;--shiki-dark:#666666">  </span><span style="color:#1e754f;--shiki-dark:#4d9375">{</span><span style="color:#99841877;--shiki-dark:#B8A96577">"</span><span style="color:#998418;--shiki-dark:#B8A965">name</span><span style="color:#99841877;--shiki-dark:#B8A96577">"</span><span style="color:#999999;--shiki-dark:#666666">:</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> "</span><span style="color:#B56959;--shiki-dark:#C98A7D">Bob</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#99841877;--shiki-dark:#B8A96577"> "</span><span style="color:#998418;--shiki-dark:#B8A965">age</span><span style="color:#99841877;--shiki-dark:#B8A96577">"</span><span style="color:#999999;--shiki-dark:#666666">:</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 30</span><span style="color:#1e754f;--shiki-dark:#4d9375">}</span></span>
<span class="line"><span style="color:#2993a3;--shiki-dark:#5eaab5">]</span></span></code></pre>
<ol start="7">
<li>写入 JSON 文件：<code>df.to_json()</code></li>
</ol>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-python"><span class="line"><span style="color:#393A34;--shiki-dark:#DBD7CAEE">df</span><span style="color:#999999;--shiki-dark:#666666">.</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">to_json</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">output.json</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> orient</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">records</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#999999;--shiki-dark:#666666">,</span><span style="color:#B07D48;--shiki-dark:#BD976A"> force_ascii</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#1E754F;--shiki-dark:#4D9375">False</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>orient</code></td>
<td>结构方式，如 <code>records</code>, <code>split</code>, <code>index</code> 等</td>
</tr>
<tr>
<td><code>force_ascii</code></td>
<td>中文是否转义为 ASCII，设为 False 保留中文</td>
</tr>
</tbody>
</table>
<hr>
<table>
<thead>
<tr>
<th>文件类型</th>
<th>读取函数</th>
<th>写入函数</th>
<th>支持多表</th>
<th>编码设置</th>
</tr>
</thead>
<tbody>
<tr>
<td>CSV</td>
<td><code>pd.read_csv()</code></td>
<td><code>df.to_csv()</code></td>
<td>否</td>
<td>支持</td>
</tr>
<tr>
<td>Excel</td>
<td><code>pd.read_excel()</code></td>
<td><code>df.to_excel()</code></td>
<td>是</td>
<td>一般无需</td>
</tr>
<tr>
<td>JSON</td>
<td><code>pd.read_json()</code></td>
<td><code>df.to_json()</code></td>
<td>否</td>
<td>支持</td>
</tr>
</tbody>
</table>
<h3 id="pandas实现数据清洗"><a class="anchor" href="#pandas实现数据清洗">#</a> Pandas实现数据清洗</h3>
<ol>
<li>清理空值</li>
</ol>
<p>首先可以在读取文件的时候自定义空值</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">missing_values</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">n/a</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">na</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> "</span><span style="color:#B56959;--shiki-dark:#C98A7D">--</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">]#自定义缺失值</span></span>
<span class="line"><span style="color:#B07D48;--shiki-dark:#BD976A">df</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">pd.read_csv</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#59873A;--shiki-dark:#80A665">"./data/csv/property-data.csv"</span><span style="color:#59873A;--shiki-dark:#80A665">,na_values</span><span style="color:#B56959;--shiki-dark:#C98A7D">=missing_values</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span></span></code></pre>
<p>利用dropna方法清理空值</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df.dropna</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">axis</span><span style="color:#B56959;--shiki-dark:#C98A7D">=0,how=</span><span style="color:#59873A;--shiki-dark:#80A665">'any'</span><span style="color:#59873A;--shiki-dark:#80A665">,thresh</span><span style="color:#B56959;--shiki-dark:#C98A7D">=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> subset=None,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> inplace=True</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:#A0ADA0;--shiki-dark:#758575DD">#inplace=True表示在原数据上修改</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">df</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">NUM_BEDROOMS</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#59873A;--shiki-dark:#80A665">.isnull</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">df.to_string</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span></code></pre>
<ol start="2">
<li>替换空单元格</li>
</ol>
<p>常用方法是计算列的均值、中位数值或众数:</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">missing_values</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">n/a</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">na</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> "</span><span style="color:#B56959;--shiki-dark:#C98A7D">--</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">]#自定义缺失值</span></span>
<span class="line"><span style="color:#B07D48;--shiki-dark:#BD976A">df</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">pd.read_csv</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#59873A;--shiki-dark:#80A665">"./data/csv/property-data.csv"</span><span style="color:#59873A;--shiki-dark:#80A665">,na_values</span><span style="color:#B56959;--shiki-dark:#C98A7D">=missing_values</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">x</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> df[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">ST_NUM</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">].mean</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">x</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#59873A;--shiki-dark:#80A665">"ST_NUM"</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#59873A;--shiki-dark:#80A665">.fillna</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> inplace</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> True</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">df.to_string</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span></span></code></pre>
<ol start="3">
<li>清洗格式错误数据</li>
</ol>
<p>利用to_datetime进行处理</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> {</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">  "Date"</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">2020/12/01</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">2020/12/02</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D"> ,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> '</span><span style="color:#B56959;--shiki-dark:#C98A7D">20201226</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">],</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">  "duration"</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">50, </span><span style="color:#B56959;--shiki-dark:#C98A7D">40,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 45]</span></span>
<span class="line"><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> pd.DataFrame</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">data,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> index</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">day1</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">day2</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> "</span><span style="color:#B56959;--shiki-dark:#C98A7D">day3</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">]</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#a65e2b;--shiki-dark:#d4976c">[</span><span style="color:#59873A;--shiki-dark:#80A665">'Date'</span><span style="color:#a65e2b;--shiki-dark:#d4976c">]</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> pd.to_datetime</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#a13865;--shiki-dark:#d9739f">[</span><span style="color:#59873A;--shiki-dark:#80A665">'Date'</span><span style="color:#a13865;--shiki-dark:#d9739f">]</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">df.to_string</span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span></code></pre>
<ol start="4">
<li>清洗错误数据</li>
</ol>
<p>利用loc(index,head)+if判断条件处理修改异常数据</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">person</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> {</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">  "name"</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Google</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Runoob</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D"> ,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> '</span><span style="color:#B56959;--shiki-dark:#C98A7D">Taobao</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">],</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">  "age"</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">50, </span><span style="color:#B56959;--shiki-dark:#C98A7D">40,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 12345]</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">    # 12345 年龄数据是错误的</span></span>
<span class="line"><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> pd.DataFrame</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">person</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">for</span><span style="color:#B07D48;--shiki-dark:#BD976A"> x</span><span style="color:#1E754F;--shiki-dark:#4D9375"> in</span><span style="color:#B56959;--shiki-dark:#C98A7D"> df.index:</span></span>
<span class="line"><span style="color:#1E754F;--shiki-dark:#4D9375">  if</span><span style="color:#59873A;--shiki-dark:#80A665"> df.loc</span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> "</span><span style="color:#B56959;--shiki-dark:#C98A7D">age</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">]</span><span style="color:#AB5959;--shiki-dark:#CB7676"> </span><span style="color:#AB5959;--shiki-dark:#CB7676">&gt;</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 120:</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    df.loc</span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#59873A;--shiki-dark:#80A665">x,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> "</span><span style="color:#B56959;--shiki-dark:#C98A7D">age</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">"</span><span style="color:#B56959;--shiki-dark:#C98A7D">]</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#2F798A;--shiki-dark:#4C9A91"> 120</span></span>
<span class="line"></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#bda437;--shiki-dark:#e6cc77">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">df.to_string</span><span style="color:#296aa3;--shiki-dark:#6394bf">(</span><span style="color:#296aa3;--shiki-dark:#6394bf">)</span><span style="color:#bda437;--shiki-dark:#e6cc77">)</span></span></code></pre>
<ol start="5">
<li>清洗重复数据</li>
</ol>
<p>利用<code>drop_duplicates</code>方法</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">persons</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> {</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">  "name"</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Google</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">, </span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">Runoob</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> '</span><span style="color:#B56959;--shiki-dark:#C98A7D">Runoob</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">,</span><span style="color:#B5695977;--shiki-dark:#C98A7D77"> '</span><span style="color:#B56959;--shiki-dark:#C98A7D">Taobao</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">],</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">  "age"</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">50, </span><span style="color:#B56959;--shiki-dark:#C98A7D">40,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 40,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 23]</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">  </span></span>
<span class="line"><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#B07D48;--shiki-dark:#BD976A">df</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B56959;--shiki-dark:#C98A7D">pd.DataFrame</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">persons</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df.drop_duplicates</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#59873A;--shiki-dark:#80A665">inplace</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> True</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#a65e2b;--shiki-dark:#d4976c">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">df</span><span style="color:#a65e2b;--shiki-dark:#d4976c">)</span></span>
<span class="line"></span></code></pre>
<ol start="6">
<li>数据归一化和标准化</li>
</ol>
<p><code>StandardScaler()</code>标准化:将数据转换为均值为0，标准差为1的分布。</p>
<p><code>MinMaxScaler()</code>归一化:将数据缩放到指定的范围（如 [0, 1]）</p>
<p><code>StandardScaler</code> 和 <code>MinMaxScaler</code> ，都是来自 sklearn.preprocessing 模块的特征缩放器（scalers）</p>
<p>调用实例:</p>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">from</span><span style="color:#B56959;--shiki-dark:#C98A7D"> sklearn.preprocessing</span><span style="color:#B56959;--shiki-dark:#C98A7D"> import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> MinMaxScaler</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">scaler</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> MinMaxScaler</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 实例化</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#2993a3;--shiki-dark:#5eaab5">[</span><span style="color:#59873A;--shiki-dark:#80A665">'ST_NUM'</span><span style="color:#2993a3;--shiki-dark:#5eaab5">]</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> scaler.fit_transform</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#1e754f;--shiki-dark:#4d9375">[</span><span style="color:#a65e2b;--shiki-dark:#d4976c">[</span><span style="color:#59873A;--shiki-dark:#80A665">'ST_NUM'</span><span style="color:#a65e2b;--shiki-dark:#d4976c">]</span><span style="color:#1e754f;--shiki-dark:#4d9375">]</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span><span style="color:#A0ADA0;--shiki-dark:#758575DD">  # 注意要用双中括号保持 DataFrame 结构</span></span>
<span class="line"></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#2993a3;--shiki-dark:#5eaab5">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">df.to_string</span><span style="color:#1e754f;--shiki-dark:#4d9375">(</span><span style="color:#1e754f;--shiki-dark:#4d9375">)</span><span style="color:#2993a3;--shiki-dark:#5eaab5">)</span></span>
<span class="line"></span></code></pre>
<table>
<thead>
<tr>
<th>特性</th>
<th>归一化（Normalization）</th>
<th>标准化（Standardization）</th>
</tr>
</thead>
<tbody>
<tr>
<td>范围</td>
<td>通常压缩到 <code>[0, 1]</code></td>
<td>没有限定范围（均值为 0）</td>
</tr>
<tr>
<td>公式</td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x - min)/(max - min)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">min</span><span class="mclose">)</span><span class="mord">/</span><span class="mopen">(</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">min</span><span class="mclose">)</span></span></span></span></td>
<td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>μ</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>σ</mi></mrow><annotation encoding="application/x-tex">(x - μ)/σ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span></td>
</tr>
<tr>
<td>是否受异常值影响</td>
<td>容易受影响</td>
<td>相对不敏感</td>
</tr>
<tr>
<td>适合算法</td>
<td>KNN、SVM、距离类算法</td>
<td>线性模型、神经网络等</td>
</tr>
</tbody>
</table>
<h3 id="pandas求解数据的相关性"><a class="anchor" href="#pandas求解数据的相关性">#</a> Pandas求解数据的相关性</h3>
<ul>
<li>皮尔逊相关系数(Pearson)：衡量两个变量之间线性关系强度和方向的指标，值域在 [-1, 1] 之间。</li>
<li>斯皮尔曼等级相关系数(Spearman)：衡量两个变量的单调关系（即一个变量增加，另一个是否总是增加或总是减少，不要求线性）</li>
<li>肯德尔秩相关系数(kendall):衡量两个变量之间排名的一致性（秩的“方向一致”程度）。</li>
<li>相关性矩阵：用来查看各个变量之间的相关性。</li>
<li>热图：一种有效的可视化方式，可以帮助我们直观地查看变量之间的相关性。</li>
</ul>
<pre class="shiki shiki-themes vitesse-light vitesse-dark" style="background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee" tabindex="0"><code class="language-bash"><span class="line"><span style="color:#59873A;--shiki-dark:#80A665">import</span><span style="color:#B56959;--shiki-dark:#C98A7D"> pandas</span><span style="color:#B56959;--shiki-dark:#C98A7D"> as</span><span style="color:#B56959;--shiki-dark:#C98A7D"> pd</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 示例数据</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">data</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> {</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    'Height'</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">150, </span><span style="color:#B56959;--shiki-dark:#C98A7D">160,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 170,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 180,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 190],</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    'Weight'</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">45, </span><span style="color:#B56959;--shiki-dark:#C98A7D">55,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 65,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 75,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 85],</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">    'Age'</span><span style="color:#998418;--shiki-dark:#B8A965">:</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE"> </span><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">[</span><span style="color:#393A34;--shiki-dark:#DBD7CAEE">20, </span><span style="color:#B56959;--shiki-dark:#C98A7D">25,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 30,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 35,</span><span style="color:#B56959;--shiki-dark:#C98A7D"> 40]</span></span>
<span class="line"><span style="color:rgba(255, 18, 18, 0.8);--shiki-dark:rgba(255, 18, 18, 0.8)">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">df</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> pd.DataFrame</span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#59873A;--shiki-dark:#80A665">data</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A0ADA0;--shiki-dark:#758575DD"># 计算皮尔逊相关系数</span></span>
<span class="line"><span style="color:#59873A;--shiki-dark:#80A665">correlation</span><span style="color:#B56959;--shiki-dark:#C98A7D"> =</span><span style="color:#B56959;--shiki-dark:#C98A7D"> df.corr</span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#B07D48;--shiki-dark:#BD976A">method</span><span style="color:#999999;--shiki-dark:#666666">=</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#B56959;--shiki-dark:#C98A7D">pearson</span><span style="color:#B5695977;--shiki-dark:#C98A7D77">'</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span></span>
<span class="line"><span style="color:#998418;--shiki-dark:#B8A965">print</span><span style="color:#a13865;--shiki-dark:#d9739f">(</span><span style="color:#B56959;--shiki-dark:#C98A7D">correlation</span><span style="color:#a13865;--shiki-dark:#d9739f">)</span></span></code></pre>
<p>切换corr里面method值就是利用不同的方法求解相关系数</p>
<div class="tags"><a href="/tags/deeplearning/" rel="tag"><i class="ic i-tag"></i>deeplearning</a><a href="/tags/pytorch/" rel="tag"><i class="ic i-tag"></i>pytorch</a><a href="/tags/Transformer/" rel="tag"><i class="ic i-tag"></i>Transformer</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">更新于 </span><time title="修改时间：2025-09-15 21:57:34" itemprop="dateModified" datetime="2025-09-15T21:57:34+08:00">2025-09-15</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img loading="lazy" src="/assets/wechatpay.png" alt="koen 微信支付"/><p>微信支付</p></div><div><img loading="lazy" src="/assets/alipay.png" alt="koen 支付宝"/><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者：</strong>koen<i class="ic i-at"><em>@</em></i>木语</li><li class="link"><strong>本文链接：</strong><a href="https://koen666.github.io/2025/07/26/pytorch/" title="Pytorch，深度学习与神经网络篇">https://koen666.github.io/2025/07/26/pytorch/</a></li><li class="license"><strong>版权声明：</strong>本站所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2025/07/26/curl/" rel="prev" itemprop="url" data-background-image="&#x2F;images&#x2F;bg&#x2F;%E3%80%90%E5%93%B2%E9%A3%8E%E5%A3%81%E7%BA%B8%E3%80%91%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9-%E6%B5%B7%E6%B4%8B%E5%A5%B3%E5%AD%A9.png" title="curl使用教学"><span class="type">上一篇</span><span class="category"><i class="ic i-flag"></i>cmd</span><h3>curl使用教学</h3></a></div><div class="item right"><a href="/2025/07/27/latex/" rel="next" itemprop="url" data-background-image="&#x2F;images&#x2F;bg&#x2F;R.png" title="Latex常见数学公式"><span class="type">下一篇</span><span class="category"><i class="ic i-flag"></i>code</span><h3>Latex常见数学公式</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-autograd"><span class="toc-number">1.</span> <span class="toc-text"> 一、AutoGrad</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text"> 二、神经网络基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-%E4%BA%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">2.1.</span> <span class="toc-text"> 2.1 了解神经网络结构的分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-%E4%BA%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%95%B4%E4%B8%AA%E8%BF%87%E7%A8%8B"><span class="toc-number">2.2.</span> <span class="toc-text"> 2.2 了解神经网络的整个过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">2.3.</span> <span class="toc-text"> 2.3激活函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.4.</span> <span class="toc-text"> 2.4损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">2.5.</span> <span class="toc-text"> 2.5优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#26%E6%95%B4%E4%B8%AA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%87%E7%A8%8B"><span class="toc-number">2.6.</span> <span class="toc-text"> 2.6整个神经网络过程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86%E5%92%8C%E5%8A%A0%E8%BD%BD"><span class="toc-number">3.</span> <span class="toc-text"> 三、数据的处理和加载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31dataset%E5%92%8Cdataloader"><span class="toc-number">3.1.</span> <span class="toc-text"> 3.1Dataset和DataLoader</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32%E5%AF%B9%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%92%8C%E5%A2%9E%E5%BC%BA"><span class="toc-number">3.2.</span> <span class="toc-text"> 3.2对图像数据预处理和增强</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-pytorch-transforms"><span class="toc-number">3.3.</span> <span class="toc-text"> 3.3 pytorch---transforms</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">4.</span> <span class="toc-text"> 四、线性回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">5.</span> <span class="toc-text"> 五、卷积神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">6.</span> <span class="toc-text"> 六、循环神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#61%E7%90%86%E8%A7%A3%E5%BE%AA%E7%8E%AFrnn"><span class="toc-number">6.1.</span> <span class="toc-text"> 6.1理解循环RNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#62rnn%E5%AE%9E%E9%99%85%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.2.</span> <span class="toc-text"> 6.2RNN实际实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83-transformer%E6%9E%B6%E6%9E%84"><span class="toc-number">7.</span> <span class="toc-text"> 七、 Transformer架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#71-%E4%BB%80%E4%B9%88%E6%98%AFtransformer%E6%9E%B6%E6%9E%84"><span class="toc-number">7.1.</span> <span class="toc-text"> 7.1 什么是transformer架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#72-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">7.2.</span> <span class="toc-text"> 7.2 注意力机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#73-transformer%E6%9E%B6%E6%9E%84%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E7%90%86"><span class="toc-number">7.3.</span> <span class="toc-text"> 7.3 transformer架构的实现机理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB-torch%E5%86%85%E5%B8%B8%E8%A7%81%E5%87%BD%E6%95%B0"><span class="toc-number">8.</span> <span class="toc-text"> 八、torch内常见函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%95%AA%E5%A4%96%E4%B8%80-pyplot"><span class="toc-number">9.</span> <span class="toc-text"> 番外一、pyplot</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E5%9F%BA%E6%9C%AC%E7%BB%98%E5%9B%BE%E6%B5%81%E7%A8%8B"><span class="toc-number">9.1.</span> <span class="toc-text"> 1.基本绘图流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E7%BD%91%E6%A0%BC%E7%BA%BF"><span class="toc-number">9.2.</span> <span class="toc-text"> 2.网格线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E7%BB%98%E5%88%B6%E5%A4%9A%E5%9B%BE"><span class="toc-number">9.3.</span> <span class="toc-text"> 3.绘制多图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E6%95%A3%E7%82%B9%E6%9F%B1%E5%BD%A2%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%92%8C%E9%A5%BC%E5%9B%BEs"><span class="toc-number">9.4.</span> <span class="toc-text"> 3.散点，柱形,直方图和饼图s</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E6%95%A3%E7%82%B9%E5%9B%BE"><span class="toc-number">9.4.1.</span> <span class="toc-text"> 1.散点图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E6%9F%B1%E5%BD%A2%E5%9B%BE"><span class="toc-number">9.4.2.</span> <span class="toc-text"> 2.柱形图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E9%A5%BC%E5%9B%BE"><span class="toc-number">9.4.3.</span> <span class="toc-text"> 3.饼图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="toc-number">9.4.4.</span> <span class="toc-text"> 4.直方图</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4imshowimsaveimread"><span class="toc-number">9.5.</span> <span class="toc-text"> 4.imshow,imsave,imread</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%95%AA%E5%A4%96%E4%BA%8C-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AF%87"><span class="toc-number">10.</span> <span class="toc-text"> 番外二、数据处理篇</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pandas%E6%93%8D%E4%BD%9C%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE"><span class="toc-number">10.1.</span> <span class="toc-text"> Pandas操作外部数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pandas%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97"><span class="toc-number">10.2.</span> <span class="toc-text"> Pandas实现数据清洗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pandas%E6%B1%82%E8%A7%A3%E6%95%B0%E6%8D%AE%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-number">10.3.</span> <span class="toc-text"> Pandas求解数据的相关性</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li  class="active"><a href="/2025/07/26/pytorch/" rel="bookmark" title="Pytorch，深度学习与神经网络篇">Pytorch，深度学习与神经网络篇</a></li><li ><a href="/2025/09/15/%E4%BB%8Edataset%E5%88%B0dataloader/" rel="bookmark" title="从datase到dataloader的过程究竟是什么">从datase到dataloader的过程究竟是什么</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="koen" src="/images/head.png"/><p class="name" itemprop="name">koen</p><div class="description" itemprop="description">Spark!</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">34</span><span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">16</span><span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">62</span><span class="name">标签</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/yourname" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;yourname"><i class="ic i-github"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li></div></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2025/07/27/latex/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2025/07/26/curl/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div><div id="player"></div></main><footer id="footer"><div class="inner"><div class="widgets"></div><div class="status"><div class="copyright">&copy; 2022 -<span itemprop="copyrightYear">2026</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">koen @ 木语</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="站点总字数">204k 字</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="站点阅读时长">3:06</span></div><div class="powered-by">基于 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
    path: `2025/07/26/pytorch/`,
    favicon: {
        show: `（●′3｀●）一切正常`,
        hide: `(′Д｀) 出问题啦！`
    },
    search: {
        placeholder: "文章搜索",
        empty: "关于 「 ${query} 」，什么也没搜到",
        stats: "${time} ms 内找到 ${hits} 条结果"
    },
    nocopy: "false",
    copyright: `复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。`,
    copy_tex: false,
    katex: false,
    mermaid: false,
    audio: undefined,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">文章时效性提示</span><br>这是一篇发布于 {{publish}} 天前，最后一次更新在 {{updated}} 天前的文章，部分信息可能已经发生改变，请注意甄别。</p></div>`,
    quiz: {
        choice: `单选题`,
        multiple: `多选题`,
        true_false: `判断题`,
        essay: `问答题`,
        gap_fill: `填空题`,
        mistake: `错题备注`
    }
};
</script><script src="/js/siteInit.js?v=0.5.4" type="module" fetchpriority="high" defer></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>