{
    "version": "https://jsonfeed.org/version/1",
    "title": "木语 • All posts by \"data\" tag",
    "description": "Spark!",
    "home_page_url": "https://koen666.github.io",
    "items": [
        {
            "id": "https://koen666.github.io/2025/10/05/%E5%A4%9Agpu/",
            "url": "https://koen666.github.io/2025/10/05/%E5%A4%9Agpu/",
            "title": "多gpu训练方式",
            "date_published": "2025-10-04T16:00:00.000Z",
            "content_html": "<h2 id=\"一-为什么需要多-gpu\"><a class=\"anchor\" href=\"#一-为什么需要多-gpu\">#</a> 一、为什么需要多 GPU？</h2>\n<p>当我们训练深度学习模型（特别是大模型）时，单张 GPU 往往不够：</p>\n<ul>\n<li>数据太大，单卡放不下；</li>\n<li>模型太复杂，训练太慢；</li>\n<li>想更快训练完成。</li>\n</ul>\n<p>于是就有了「<strong>多 GPU 训练</strong>」这个想法：<br>\n<strong>让多张显卡一起干活，分担计算任务。</strong></p>\n<hr>\n<h2 id=\"二-多-gpu-的三种主要方式\"><a class=\"anchor\" href=\"#二-多-gpu-的三种主要方式\">#</a> 二、多 GPU 的三种主要方式</h2>\n<p>多 GPU 的实现方式有很多，但核心分为三类</p>\n<table>\n<thead>\n<tr>\n<th>方式</th>\n<th>中文名称</th>\n<th>思路</th>\n<th>优缺点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1️⃣ 模型并行（Model Parallel）</td>\n<td>模型拆开</td>\n<td>把模型的不同层分给不同 GPU</td>\n<td>适合模型太大放不下一张卡；通信频繁，实现复杂</td>\n</tr>\n<tr>\n<td>2️⃣ 数据并行（Data Parallel）</td>\n<td>数据拆开</td>\n<td>模型每张卡都复制一份，每张卡训练一部分数据</td>\n<td>通用、最常见</td>\n</tr>\n<tr>\n<td>3️⃣ 分布式数据并行（Distributed Data Parallel, DDP）</td>\n<td>高效数据并行</td>\n<td>每张卡独立进程，自动同步梯度</td>\n<td>工业级方案，最快、最稳定</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"三-核心思想数据并行\"><a class=\"anchor\" href=\"#三-核心思想数据并行\">#</a> 三、核心思想：数据并行</h2>\n<p>多 GPU 训练中，<strong>数据并行</strong>是最常用的方式。</p>\n<p>其思想非常简单：</p>\n<blockquote>\n<p><strong>模型每张卡都有一份副本；每张卡训练不同部分的数据；最后汇总结果。</strong></p>\n</blockquote>\n<p>假设你有 2 张 GPU，每次 batch 有 4 张图片：</p>\n<pre class=\"shiki shiki-themes vitesse-light vitesse-dark\" style=\"background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee\" tabindex=\"0\"><code class=\"language-text\"><span class=\"line\"><span>批次数据： [1, 2, 3, 4]</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>GPU0 ← [1, 2]</span></span>\n<span class=\"line\"><span>GPU1 ← [3, 4]</span></span></code></pre>\n<p>训练流程<br>\n1️⃣ 每张 GPU 都有一份相同的模型副本。<br>\n2️⃣ 各 GPU 前向计算 → 得到自己的 loss。<br>\n3️⃣ 各 GPU 反向传播 → 得到自己的梯度。<br>\n4️⃣ <strong>梯度同步（allreduce）</strong> → 求平均。<br>\n5️⃣ 各 GPU 同步更新参数。</p>\n<p>这样每张 GPU 的参数始终保持一致。</p>\n<hr>\n<h2 id=\"四-关键概念详解\"><a class=\"anchor\" href=\"#四-关键概念详解\">#</a> 四、关键概念详解</h2>\n<p>下面是训练中会出现的一些关键术语</p>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>train</strong></td>\n<td>训练集，用于更新模型参数。</td>\n</tr>\n<tr>\n<td><strong>val (validation)</strong></td>\n<td>验证集，用于评估模型是否过拟合，不参与训练。</td>\n</tr>\n<tr>\n<td><strong>test</strong></td>\n<td>测试集，用于最终测试模型效果。</td>\n</tr>\n<tr>\n<td><strong>query</strong></td>\n<td>查询集，常见于检索任务，用来搜索匹配结果。</td>\n</tr>\n<tr>\n<td><strong>gallery / bounding_box</strong></td>\n<td>检索任务中的数据库部分（比如人脸库、行人库）。</td>\n</tr>\n<tr>\n<td><strong>batch（批次）</strong></td>\n<td>一次喂给模型的数据量。</td>\n</tr>\n<tr>\n<td><strong>split_batch</strong></td>\n<td>把一个 batch 的数据拆成几份给不同 GPU。</td>\n</tr>\n<tr>\n<td><strong>allreduce</strong></td>\n<td>把多 GPU 的梯度相加、平均，让模型参数保持一致。</td>\n</tr>\n<tr>\n<td><strong>scatter</strong></td>\n<td>把数据分发到多个 GPU。</td>\n</tr>\n<tr>\n<td><strong>gather / concat</strong></td>\n<td>把多个 GPU 的结果合并回来。</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"五-三种实现方式详解\"><a class=\"anchor\" href=\"#五-三种实现方式详解\">#</a> 五、三种实现方式详解</h2>\n<h3 id=\"1️⃣-模型并行model-parallel\"><a class=\"anchor\" href=\"#1️⃣-模型并行model-parallel\">#</a> 1️⃣ 模型并行（Model Parallel）</h3>\n<p><strong>思想：</strong></p>\n<blockquote>\n<p>模型太大，一张卡放不下，就把不同层放到不同 GPU 上。</p>\n</blockquote>\n<p>示意：</p>\n<pre class=\"shiki shiki-themes vitesse-light vitesse-dark\" style=\"background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee\" tabindex=\"0\"><code class=\"language-text\"><span class=\"line\"><span>GPU0: 负责模型前半部分</span></span>\n<span class=\"line\"><span>GPU1: 负责模型后半部分</span></span></code></pre>\n<p><strong>特点：</strong></p>\n<ul>\n<li>模型能变得更大；</li>\n<li>但通信频繁，效率不高；</li>\n<li>实现较复杂。</li>\n</ul>\n<p>适用：GPT、BERT 这类超大模型。</p>\n<hr>\n<h3 id=\"2️⃣-数据并行data-paralleldp\"><a class=\"anchor\" href=\"#2️⃣-数据并行data-paralleldp\">#</a> 2️⃣ 数据并行（Data Parallel，DP）</h3>\n<p><strong>思想：</strong></p>\n<blockquote>\n<p>每张卡都有一份完整模型副本，但处理不同部分的数据。</p>\n</blockquote>\n<p>PyTorch 用法：</p>\n<pre class=\"shiki shiki-themes vitesse-light vitesse-dark\" style=\"background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee\" tabindex=\"0\"><code class=\"language-python\"><span class=\"line\"><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">model </span><span style=\"color:#999999;--shiki-dark:#666666\">=</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"color:#999999;--shiki-dark:#666666\">.</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"color:#999999;--shiki-dark:#666666\">.</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">DataParallel</span><span style=\"color:#2993a3;--shiki-dark:#5eaab5\">(</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">model</span><span style=\"color:#2993a3;--shiki-dark:#5eaab5\">)</span></span></code></pre>\n<p><strong>流程：</strong></p>\n<ol>\n<li>数据被平均分配给每张 GPU（scatter）。</li>\n<li>各 GPU 前向 &amp; 反向传播。</li>\n<li>主 GPU（GPU0）收集所有梯度，求平均。</li>\n<li>GPU0 更新参数，再广播回所有 GPU。</li>\n</ol>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>GPU0 负担过重（通信瓶颈）；</li>\n<li>不能多机训练。</li>\n</ul>\n<p>适用：快速实验、小模型。</p>\n<hr>\n<h3 id=\"3️⃣-分布式数据并行distributed-data-parallelddp\"><a class=\"anchor\" href=\"#3️⃣-分布式数据并行distributed-data-parallelddp\">#</a> 3️⃣ 分布式数据并行（Distributed Data Parallel，DDP）</h3>\n<p><strong>思想：</strong></p>\n<blockquote>\n<p>数据并行的改进版，每张 GPU 独立进程，自动通信同步。</p>\n</blockquote>\n<p>PyTorch 用法：</p>\n<pre class=\"shiki shiki-themes vitesse-light vitesse-dark\" style=\"background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee\" tabindex=\"0\"><code class=\"language-python\"><span class=\"line\"><span style=\"color:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"color:#999999;--shiki-dark:#666666\">.</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"color:#999999;--shiki-dark:#666666\">.</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">parallel </span><span style=\"color:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\"> DistributedDataParallel </span><span style=\"color:#1E754F;--shiki-dark:#4D9375\">as</span><span style=\"color:#A65E2B;--shiki-dark:#C99076\"> DDP</span></span>\n<span class=\"line\"><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">model </span><span style=\"color:#999999;--shiki-dark:#666666\">=</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\"> DDP</span><span style=\"color:#2993a3;--shiki-dark:#5eaab5\">(</span><span style=\"color:#393A34;--shiki-dark:#DBD7CAEE\">model</span><span style=\"color:#2993a3;--shiki-dark:#5eaab5\">)</span></span></code></pre>\n<p><strong>流程图示（假设2张GPU）</strong></p>\n<pre class=\"shiki shiki-themes vitesse-light vitesse-dark\" style=\"background-color:#ffffff;--shiki-dark-bg:#121212;color:#393a34;--shiki-dark:#dbd7caee\" tabindex=\"0\"><code class=\"language-text\"><span class=\"line\"><span>Step 1: 复制模型</span></span>\n<span class=\"line\"><span>GPU0: 模型A</span></span>\n<span class=\"line\"><span>GPU1: 模型A</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>Step 2: 拆分数据</span></span>\n<span class=\"line\"><span>GPU0: batch[0:2]</span></span>\n<span class=\"line\"><span>GPU1: batch[2:4]</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>Step 3: 前向+反向</span></span>\n<span class=\"line\"><span>各GPU独立算梯度</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>Step 4: allreduce同步</span></span>\n<span class=\"line\"><span>梯度平均后广播到每张卡</span></span>\n<span class=\"line\"><span></span></span>\n<span class=\"line\"><span>Step 5: 更新参数（同步）</span></span></code></pre>\n<p><strong>一句话总结：</strong></p>\n<blockquote>\n<p>DDP 是 PyTorch 官方推荐的多 GPU 训练标准方案。</p>\n</blockquote>\n<hr>\n<h2 id=\"六-底层机制理解scatter-allreduce-gather\"><a class=\"anchor\" href=\"#六-底层机制理解scatter-allreduce-gather\">#</a> 六、底层机制理解：scatter / allreduce / gather</h2>\n<table>\n<thead>\n<tr>\n<th>操作</th>\n<th>作用</th>\n<th>举例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>scatter</strong></td>\n<td>拆数据</td>\n<td>把 100 张图片分成两份发到 GPU0、GPU1</td>\n</tr>\n<tr>\n<td><strong>allreduce</strong></td>\n<td>同步梯度</td>\n<td>GPU0 的梯度 + GPU1 的梯度 → 平均后广播</td>\n</tr>\n<tr>\n<td><strong>gather / concat</strong></td>\n<td>合并结果</td>\n<td>把每个 GPU 的预测拼起来做整体评估</td>\n</tr>\n</tbody>\n</table>\n<p>这些操作是 <strong>数据并行的核心通信机制</strong>。<br>\n在 DDP 中，它们是由 PyTorch 自动完成的。</p>\n<hr>\n<h2 id=\"七-在-ddp-中训练需要注意什么\"><a class=\"anchor\" href=\"#七-在-ddp-中训练需要注意什么\">#</a> 七、在 DDP 中训练需要注意什么</h2>\n<table>\n<thead>\n<tr>\n<th>事项</th>\n<th>原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>每个 GPU 独立进程</td>\n<td>保证同步和效率</td>\n</tr>\n<tr>\n<td>使用 <code>DistributedSampler</code></td>\n<td>自动分配数据给不同 GPU</td>\n</tr>\n<tr>\n<td>设置环境变量（rank, world_size）</td>\n<td>标识 GPU 编号和总数</td>\n</tr>\n<tr>\n<td>初始化通信（init_process_group）</td>\n<td>建立 NCCL 通信通道</td>\n</tr>\n<tr>\n<td>每个进程保存日志、模型</td>\n<td>避免覆盖</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"八-三个阶段的总结对比表\"><a class=\"anchor\" href=\"#八-三个阶段的总结对比表\">#</a> 八、三个阶段的总结对比表</h2>\n<table>\n<thead>\n<tr>\n<th>阶段</th>\n<th>干的事</th>\n<th>特点</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>模型并行</td>\n<td>模型拆分</td>\n<td>各 GPU 存不同层</td>\n<td>GPT、BERT</td>\n</tr>\n<tr>\n<td>数据并行（DP）</td>\n<td>数据拆分 + 主卡同步</td>\n<td>简单但低效</td>\n<td><code>nn.DataParallel</code></td>\n</tr>\n<tr>\n<td>分布式数据并行（DDP）</td>\n<td>数据拆分 + 自动同步</td>\n<td>高效工业级</td>\n<td><code>DistributedDataParallel</code></td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"九-类比理解多-gpu-像工厂流水线\"><a class=\"anchor\" href=\"#九-类比理解多-gpu-像工厂流水线\">#</a> 九、类比理解：多 GPU 像工厂流水线</h2>\n<table>\n<thead>\n<tr>\n<th>工人</th>\n<th>工作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>GPU0</td>\n<td>处理样本1-50</td>\n</tr>\n<tr>\n<td>GPU1</td>\n<td>处理样本51-100</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>每个工人有同样的手册（模型）；</li>\n<li>干完活后汇报经验（梯度）；</li>\n<li>经理平均总结经验（allreduce）；</li>\n<li>更新手册；</li>\n<li>下一轮所有人继续。</li>\n</ul>\n<p>这，就是数据并行和 DDP 的本质。</p>\n",
            "tags": [
                "gpu",
                "data"
            ]
        }
    ]
}